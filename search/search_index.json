{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Glasses \ud83d\ude0e A long way to go \ud83d\udea7 This project is WIP. We will make it perfect, but we are not still there! If you want to help out, check the Contributing Guide \ud83d\udc9c. A compact, concise, and customizable deep learning library. This library currently supports deep learning models for computer vision. Glasses is a model toolbox to make it easier for everybody to use, learn and share deep learning models. Documentation : TODO Source Code : https://github.com/FrancescoSaverioZuppichini/glasses TL;DR This library has human readable code, no research code common component are shared across models same APIs for all models (you learn them once and they are always the same) clear and easy to use model constomization (see here ) classification and segmentation easy to contribute, see the contribution guide emoji in the name ;) Requirements Python 3.8+ Installation $ pip install git+https://github.com/FrancescoSaverioZuppichini/glasses.git ---> 100% Motivations Almost all existing implementations of the most famous model are written with very bad coding practices, what today is called research code. We struggled to understand some of the implementations even if in the end were just a few lines of code. Most of them are missing a global structure, they used tons of code repetition, and they are not easily customizable and not tested. Thus, not easy to share and use by everybody. Head over the getting started guide RoadMap We plan to have three main steps in the development Models : Defined different models for different tasks, the configuration system, and how to save/load them. \u2b05\ufe0f We are here! Tasks : Defined the train/evaluation lifecycle for each task. Pipelines : Defined the whole lifecycle for a task, from data to training. Contributing Please contribute using GitHub Flow . Create a branch, add commits, and open a pull request. Please read contributing for details on our CODE OF CONDUCT, and the process for submitting pull requests to us. License\u00b6 This project is licensed under the terms of the MIT license.","title":"Glasses"},{"location":"#glasses","text":"A long way to go \ud83d\udea7 This project is WIP. We will make it perfect, but we are not still there! If you want to help out, check the Contributing Guide \ud83d\udc9c. A compact, concise, and customizable deep learning library. This library currently supports deep learning models for computer vision. Glasses is a model toolbox to make it easier for everybody to use, learn and share deep learning models. Documentation : TODO Source Code : https://github.com/FrancescoSaverioZuppichini/glasses","title":"Glasses \ud83d\ude0e"},{"location":"#tldr","text":"This library has human readable code, no research code common component are shared across models same APIs for all models (you learn them once and they are always the same) clear and easy to use model constomization (see here ) classification and segmentation easy to contribute, see the contribution guide emoji in the name ;)","title":"TL;DR"},{"location":"#requirements","text":"Python 3.8+","title":"Requirements"},{"location":"#installation","text":"$ pip install git+https://github.com/FrancescoSaverioZuppichini/glasses.git ---> 100%","title":"Installation"},{"location":"#motivations","text":"Almost all existing implementations of the most famous model are written with very bad coding practices, what today is called research code. We struggled to understand some of the implementations even if in the end were just a few lines of code. Most of them are missing a global structure, they used tons of code repetition, and they are not easily customizable and not tested. Thus, not easy to share and use by everybody. Head over the getting started guide","title":"Motivations"},{"location":"#roadmap","text":"We plan to have three main steps in the development Models : Defined different models for different tasks, the configuration system, and how to save/load them. \u2b05\ufe0f We are here! Tasks : Defined the train/evaluation lifecycle for each task. Pipelines : Defined the whole lifecycle for a task, from data to training.","title":"RoadMap"},{"location":"#contributing","text":"Please contribute using GitHub Flow . Create a branch, add commits, and open a pull request. Please read contributing for details on our CODE OF CONDUCT, and the process for submitting pull requests to us.","title":"Contributing"},{"location":"#license","text":"This project is licensed under the terms of the MIT license.","title":"License\u00b6"},{"location":"contributing/","text":"Everyone is welcome to contribute \ud83d\udc9c Please contribute using GitHub Flow . Create a branch, add commits, and open a pull request. Be sure to check our coding style guide .","title":"Contributing"},{"location":"getting-started/","text":"$ AutoModel () . from_pretrained ( \"my_name\" ) [ 06 / 21 / 22 18 : 13 : 40 ] WARNING Error ( s ) in loading state_dict for AnyModelForImageClassification : base . py : 54 Unexpected key ( s ) in state_dict : \"head.fc.weight\" , \"head.fc.bias\" . INFO Loaded pretrained weights for dummy - d0 .","title":"Getting Started"},{"location":"reference/","text":"","title":"Index"},{"location":"reference/SUMMARY/","text":"glasses config logger models auto base model_zoo utils transform transform vision auto backbones base vit config model zoo image classification base common config model heads base linear_head config model vit config model outputs vit config zoo detection outputs segmentation outputs necks base nn storage base local types","title":"SUMMARY"},{"location":"reference/logger/","text":"logger = logging . getLogger ( 'glasses' ) module-attribute","title":"logger"},{"location":"reference/logger/#glasses.logger.logger","text":"","title":"logger"},{"location":"reference/types/","text":"StateDict = Dict [ str , Tensor ] module-attribute","title":"types"},{"location":"reference/types/#glasses.types.StateDict","text":"","title":"StateDict"},{"location":"reference/config/","text":"Config dataclass Base class for configurations, all configuration must inherit from this class. For a in depth tutorial about configs, head over Configurations Important Models are not coupled with Config , therefore they are unaware of the configuration system. Each Config is linked to a specific model, not viceversa. Note A Config holds what is needed to create a model. Therefore, they are perfect to share custom version of a specific architecture. A Config is data container . Thus, it must not have any side effect , any logic that requires the Config values to be somehow processed must be implemented in the Config.build function. A custom configuration can be written as follows: from glasses.config import Config # Assume we have a model class MyModel ( nn . Module ): def __init__ ( in_channels : int , out_channels : int ): super () . __init__ () self . conv = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 ) def forward ( self , x ): return self . conv ( x ) # Let's create it's configuration @dataclass class MyConfig ( Config ): in_channels : int out_channels : int def build ( self ) -> nn . Module : # create a `MyModel` instance using `MyConfig` return MyModel ( ** self . __dict__ ) model : MyModel = MyConfig ( 2 , 2 ) . build () Each Config is linked to a specific model, not viceversa. Models had no idea about the configuration system and can be created normally as you expect with their constructor. Nested Configurations Source code in glasses/config/__init__.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @dataclass class Config : \"\"\" Base class for configurations, all configuration **must** inherit from this class. For a in depth tutorial about configs, head over [Configurations](/) !!! important Models are not coupled with `Config`, therefore they are unaware of the configuration system. Each `Config` is linked to a specific model, not viceversa. !!! note A `Config` holds what is needed to create a model. Therefore, they are perfect to share custom version of a specific architecture. A `Config` is **data container**. Thus, it **must not have any side effect**, any logic that requires the `Config` values to be somehow processed must be implemented in the [`Config.build`](#glasses.config.Config.build) function. A custom configuration can be written as follows: ```python from glasses.config import Config # Assume we have a model class MyModel(nn.Module): def __init__(in_channels: int, out_channels: int): super().__init__() self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1) def forward(self, x): return self.conv(x) # Let's create it's configuration @dataclass class MyConfig(Config): in_channels: int out_channels: int def build(self) -> nn.Module: # create a `MyModel` instance using `MyConfig` return MyModel(**self.__dict__) model: MyModel = MyConfig(2, 2).build() ``` Each Config is linked to a specific model, not viceversa. Models had no idea about the configuration system and can be created normally as you expect with their constructor. ## Nested Configurations \"\"\" def build ( self ) -> nn . Module : raise NotImplementedError def panel ( self ) -> Panel : table = Table ( title = self . __class__ . __name__ , box = box . SIMPLE , show_header = False , highlight = True , ) for key , val in self . __dict__ . items (): # if one field is a Config instance if isinstance ( val , Config ): table . add_row ( \"\" , \"\" ) table . add_row ( f \"[bold] { key } \" , val . panel ()) else : table . add_row ( key , str ( val )) return Panel ( table ) def summary ( self ): console = Console () console . print ( self . panel (), justify = \"left\" ) build () Source code in glasses/config/__init__.py 57 58 def build ( self ) -> nn . Module : raise NotImplementedError panel () Source code in glasses/config/__init__.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def panel ( self ) -> Panel : table = Table ( title = self . __class__ . __name__ , box = box . SIMPLE , show_header = False , highlight = True , ) for key , val in self . __dict__ . items (): # if one field is a Config instance if isinstance ( val , Config ): table . add_row ( \"\" , \"\" ) table . add_row ( f \"[bold] { key } \" , val . panel ()) else : table . add_row ( key , str ( val )) return Panel ( table ) summary () Source code in glasses/config/__init__.py 77 78 79 def summary ( self ): console = Console () console . print ( self . panel (), justify = \"left\" )","title":"config"},{"location":"reference/config/#glasses.config.Config","text":"Base class for configurations, all configuration must inherit from this class. For a in depth tutorial about configs, head over Configurations Important Models are not coupled with Config , therefore they are unaware of the configuration system. Each Config is linked to a specific model, not viceversa. Note A Config holds what is needed to create a model. Therefore, they are perfect to share custom version of a specific architecture. A Config is data container . Thus, it must not have any side effect , any logic that requires the Config values to be somehow processed must be implemented in the Config.build function. A custom configuration can be written as follows: from glasses.config import Config # Assume we have a model class MyModel ( nn . Module ): def __init__ ( in_channels : int , out_channels : int ): super () . __init__ () self . conv = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 ) def forward ( self , x ): return self . conv ( x ) # Let's create it's configuration @dataclass class MyConfig ( Config ): in_channels : int out_channels : int def build ( self ) -> nn . Module : # create a `MyModel` instance using `MyConfig` return MyModel ( ** self . __dict__ ) model : MyModel = MyConfig ( 2 , 2 ) . build () Each Config is linked to a specific model, not viceversa. Models had no idea about the configuration system and can be created normally as you expect with their constructor.","title":"Config"},{"location":"reference/config/#glasses.config.Config--nested-configurations","text":"Source code in glasses/config/__init__.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 @dataclass class Config : \"\"\" Base class for configurations, all configuration **must** inherit from this class. For a in depth tutorial about configs, head over [Configurations](/) !!! important Models are not coupled with `Config`, therefore they are unaware of the configuration system. Each `Config` is linked to a specific model, not viceversa. !!! note A `Config` holds what is needed to create a model. Therefore, they are perfect to share custom version of a specific architecture. A `Config` is **data container**. Thus, it **must not have any side effect**, any logic that requires the `Config` values to be somehow processed must be implemented in the [`Config.build`](#glasses.config.Config.build) function. A custom configuration can be written as follows: ```python from glasses.config import Config # Assume we have a model class MyModel(nn.Module): def __init__(in_channels: int, out_channels: int): super().__init__() self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1) def forward(self, x): return self.conv(x) # Let's create it's configuration @dataclass class MyConfig(Config): in_channels: int out_channels: int def build(self) -> nn.Module: # create a `MyModel` instance using `MyConfig` return MyModel(**self.__dict__) model: MyModel = MyConfig(2, 2).build() ``` Each Config is linked to a specific model, not viceversa. Models had no idea about the configuration system and can be created normally as you expect with their constructor. ## Nested Configurations \"\"\" def build ( self ) -> nn . Module : raise NotImplementedError def panel ( self ) -> Panel : table = Table ( title = self . __class__ . __name__ , box = box . SIMPLE , show_header = False , highlight = True , ) for key , val in self . __dict__ . items (): # if one field is a Config instance if isinstance ( val , Config ): table . add_row ( \"\" , \"\" ) table . add_row ( f \"[bold] { key } \" , val . panel ()) else : table . add_row ( key , str ( val )) return Panel ( table ) def summary ( self ): console = Console () console . print ( self . panel (), justify = \"left\" )","title":"Nested Configurations"},{"location":"reference/config/#glasses.config.Config.build","text":"Source code in glasses/config/__init__.py 57 58 def build ( self ) -> nn . Module : raise NotImplementedError","title":"build()"},{"location":"reference/config/#glasses.config.Config.panel","text":"Source code in glasses/config/__init__.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def panel ( self ) -> Panel : table = Table ( title = self . __class__ . __name__ , box = box . SIMPLE , show_header = False , highlight = True , ) for key , val in self . __dict__ . items (): # if one field is a Config instance if isinstance ( val , Config ): table . add_row ( \"\" , \"\" ) table . add_row ( f \"[bold] { key } \" , val . panel ()) else : table . add_row ( key , str ( val )) return Panel ( table )","title":"panel()"},{"location":"reference/config/#glasses.config.Config.summary","text":"Source code in glasses/config/__init__.py 77 78 79 def summary ( self ): console = Console () console . print ( self . panel (), justify = \"left\" )","title":"summary()"},{"location":"reference/models/","text":"","title":"Index"},{"location":"reference/models/auto/","text":"","title":"Index"},{"location":"reference/models/auto/base/","text":"AutoModel The base AutoModel class. Usage: auto_model = AutoModel () model = auto_model . from_name ( \"my_name\" ) model = auto_model . from_pretrained ( \"my_name\" ) model = auto_model . from_pretrained ( \"my_name\" , my_config ) Source code in glasses/models/auto/base.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 class AutoModel : \"\"\"The base `AutoModel` class. Usage: ```python auto_model = AutoModel() model = auto_model.from_name(\"my_name\") model = auto_model.from_pretrained(\"my_name\") model = auto_model.from_pretrained(\"my_name\", my_config) ``` \"\"\" names_to_configs : Dict [ str , Callable [[], Config ]] \"\"\"Holds the map from name to config type\"\"\" @classmethod def get_config_from_name ( cls , name : str ) -> Config : return cls . names_to_configs [ name ]() @classmethod def from_name ( cls , name : str ): if name not in cls . names_to_configs : suggestions = difflib . get_close_matches ( name , cls . names_to_configs . keys ()) msg = f 'Model \" { name } \" does not exists.' if len ( suggestions ) > 0 : msg += f ' Did you mean \" { suggestions [ 0 ] } ?\"' raise KeyError ( msg ) config = cls . names_to_configs [ name ]() return config . build () @classmethod def from_pretrained ( cls , name : str , config : Optional [ Config ] = None , storage : Storage = None ) -> nn . Module : storage = LocalStorage () if storage is None else storage state_dict , loaded_config = storage . get ( name ) config = loaded_config if config is None else config model = config . build () try : model . load_state_dict ( state_dict ) except RuntimeError as e : logger . warning ( str ( e )) logger . info ( f \"Loaded pretrained weights for { name } .\" ) return model , config names_to_configs : Dict [ str , Callable [[], Config ]] class-attribute Holds the map from name to config type from_name ( name ) classmethod Source code in glasses/models/auto/base.py 32 33 34 35 36 37 38 39 40 41 42 @classmethod def from_name ( cls , name : str ): if name not in cls . names_to_configs : suggestions = difflib . get_close_matches ( name , cls . names_to_configs . keys ()) msg = f 'Model \" { name } \" does not exists.' if len ( suggestions ) > 0 : msg += f ' Did you mean \" { suggestions [ 0 ] } ?\"' raise KeyError ( msg ) config = cls . names_to_configs [ name ]() return config . build () from_pretrained ( name , config = None , storage = None ) classmethod Source code in glasses/models/auto/base.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 @classmethod def from_pretrained ( cls , name : str , config : Optional [ Config ] = None , storage : Storage = None ) -> nn . Module : storage = LocalStorage () if storage is None else storage state_dict , loaded_config = storage . get ( name ) config = loaded_config if config is None else config model = config . build () try : model . load_state_dict ( state_dict ) except RuntimeError as e : logger . warning ( str ( e )) logger . info ( f \"Loaded pretrained weights for { name } .\" ) return model , config get_config_from_name ( name ) classmethod Source code in glasses/models/auto/base.py 28 29 30 @classmethod def get_config_from_name ( cls , name : str ) -> Config : return cls . names_to_configs [ name ]()","title":"base"},{"location":"reference/models/auto/base/#glasses.models.auto.base.AutoModel","text":"The base AutoModel class. Usage: auto_model = AutoModel () model = auto_model . from_name ( \"my_name\" ) model = auto_model . from_pretrained ( \"my_name\" ) model = auto_model . from_pretrained ( \"my_name\" , my_config ) Source code in glasses/models/auto/base.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 class AutoModel : \"\"\"The base `AutoModel` class. Usage: ```python auto_model = AutoModel() model = auto_model.from_name(\"my_name\") model = auto_model.from_pretrained(\"my_name\") model = auto_model.from_pretrained(\"my_name\", my_config) ``` \"\"\" names_to_configs : Dict [ str , Callable [[], Config ]] \"\"\"Holds the map from name to config type\"\"\" @classmethod def get_config_from_name ( cls , name : str ) -> Config : return cls . names_to_configs [ name ]() @classmethod def from_name ( cls , name : str ): if name not in cls . names_to_configs : suggestions = difflib . get_close_matches ( name , cls . names_to_configs . keys ()) msg = f 'Model \" { name } \" does not exists.' if len ( suggestions ) > 0 : msg += f ' Did you mean \" { suggestions [ 0 ] } ?\"' raise KeyError ( msg ) config = cls . names_to_configs [ name ]() return config . build () @classmethod def from_pretrained ( cls , name : str , config : Optional [ Config ] = None , storage : Storage = None ) -> nn . Module : storage = LocalStorage () if storage is None else storage state_dict , loaded_config = storage . get ( name ) config = loaded_config if config is None else config model = config . build () try : model . load_state_dict ( state_dict ) except RuntimeError as e : logger . warning ( str ( e )) logger . info ( f \"Loaded pretrained weights for { name } .\" ) return model , config","title":"AutoModel"},{"location":"reference/models/auto/base/#glasses.models.auto.base.AutoModel.names_to_configs","text":"Holds the map from name to config type","title":"names_to_configs"},{"location":"reference/models/auto/base/#glasses.models.auto.base.AutoModel.from_name","text":"Source code in glasses/models/auto/base.py 32 33 34 35 36 37 38 39 40 41 42 @classmethod def from_name ( cls , name : str ): if name not in cls . names_to_configs : suggestions = difflib . get_close_matches ( name , cls . names_to_configs . keys ()) msg = f 'Model \" { name } \" does not exists.' if len ( suggestions ) > 0 : msg += f ' Did you mean \" { suggestions [ 0 ] } ?\"' raise KeyError ( msg ) config = cls . names_to_configs [ name ]() return config . build ()","title":"from_name()"},{"location":"reference/models/auto/base/#glasses.models.auto.base.AutoModel.from_pretrained","text":"Source code in glasses/models/auto/base.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 @classmethod def from_pretrained ( cls , name : str , config : Optional [ Config ] = None , storage : Storage = None ) -> nn . Module : storage = LocalStorage () if storage is None else storage state_dict , loaded_config = storage . get ( name ) config = loaded_config if config is None else config model = config . build () try : model . load_state_dict ( state_dict ) except RuntimeError as e : logger . warning ( str ( e )) logger . info ( f \"Loaded pretrained weights for { name } .\" ) return model , config","title":"from_pretrained()"},{"location":"reference/models/auto/base/#glasses.models.auto.base.AutoModel.get_config_from_name","text":"Source code in glasses/models/auto/base.py 28 29 30 @classmethod def get_config_from_name ( cls , name : str ) -> Config : return cls . names_to_configs [ name ]()","title":"get_config_from_name()"},{"location":"reference/models/auto/model_zoo/","text":"ModelZoo Bases: dict Source code in glasses/models/auto/model_zoo.py 1 2 class ModelZoo ( dict ): pass","title":"model_zoo"},{"location":"reference/models/auto/model_zoo/#glasses.models.auto.model_zoo.ModelZoo","text":"Bases: dict Source code in glasses/models/auto/model_zoo.py 1 2 class ModelZoo ( dict ): pass","title":"ModelZoo"},{"location":"reference/models/auto/utils/","text":"get_names_to_configs_map ( * args , ** kwargs ) Source code in glasses/models/auto/utils.py 28 29 30 31 32 33 34 35 36 37 38 39 def get_names_to_configs_map ( * args , ** kwargs ): names_to_models_map = {} for module in iter_models_modules ( * args , ** kwargs ): submodule = importlib . import_module ( \".\" , f \" { module } .zoo\" ) try : zoo = vars ( submodule )[ \"zoo\" ] except KeyError : raise KeyError ( f \"A `zoo.py` was found in { module } but no `zoo` was defined.\" ) names_to_models_map = { ** names_to_models_map , ** zoo } return names_to_models_map iter_models_modules ( package , ignore_dirs = None ) Source code in glasses/models/auto/utils.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def iter_models_modules ( package : str , ignore_dirs : Optional [ List [ str ]] = None ) -> Iterator [ str ]: ignore_dirs = [] if ignore_dirs is None else ignore_dirs # the following folders will be skipeed by default ignore_dirs += [ \"auto\" , \"heads\" , \"__pycache__\" , \"common\" ] # we import the package module = importlib . import_module ( \".\" , package ) if not module . __file__ : raise ModuleNotFoundError ( f \" { package } doesn't exist.\" ) # and we get the path to the folder it's contained module_path = Path ( module . __file__ ) . parent # then we iterate all the subdirs and we look for packages to import for file_or_dir in module_path . iterdir (): # if we have found a dir and it's not in ignore is_valid_dir = file_or_dir . is_dir () and file_or_dir . stem not in ignore_dirs if is_valid_dir : has_a_config = ( file_or_dir / \"config.py\" ) . exists () if has_a_config : yield f \" { package } . { file_or_dir . stem } \"","title":"utils"},{"location":"reference/models/auto/utils/#glasses.models.auto.utils.get_names_to_configs_map","text":"Source code in glasses/models/auto/utils.py 28 29 30 31 32 33 34 35 36 37 38 39 def get_names_to_configs_map ( * args , ** kwargs ): names_to_models_map = {} for module in iter_models_modules ( * args , ** kwargs ): submodule = importlib . import_module ( \".\" , f \" { module } .zoo\" ) try : zoo = vars ( submodule )[ \"zoo\" ] except KeyError : raise KeyError ( f \"A `zoo.py` was found in { module } but no `zoo` was defined.\" ) names_to_models_map = { ** names_to_models_map , ** zoo } return names_to_models_map","title":"get_names_to_configs_map()"},{"location":"reference/models/auto/utils/#glasses.models.auto.utils.iter_models_modules","text":"Source code in glasses/models/auto/utils.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def iter_models_modules ( package : str , ignore_dirs : Optional [ List [ str ]] = None ) -> Iterator [ str ]: ignore_dirs = [] if ignore_dirs is None else ignore_dirs # the following folders will be skipeed by default ignore_dirs += [ \"auto\" , \"heads\" , \"__pycache__\" , \"common\" ] # we import the package module = importlib . import_module ( \".\" , package ) if not module . __file__ : raise ModuleNotFoundError ( f \" { package } doesn't exist.\" ) # and we get the path to the folder it's contained module_path = Path ( module . __file__ ) . parent # then we iterate all the subdirs and we look for packages to import for file_or_dir in module_path . iterdir (): # if we have found a dir and it's not in ignore is_valid_dir = file_or_dir . is_dir () and file_or_dir . stem not in ignore_dirs if is_valid_dir : has_a_config = ( file_or_dir / \"config.py\" ) . exists () if has_a_config : yield f \" { package } . { file_or_dir . stem } \"","title":"iter_models_modules()"},{"location":"reference/models/transform/","text":"","title":"Index"},{"location":"reference/models/transform/transform/","text":"ApplyToKeys dataclass Source code in glasses/models/transform/transform.py 5 6 7 8 9 10 11 12 13 14 @dataclass class ApplyToKeys : transform : Callable keys : List [ str ] def __call__ ( self , data : Dict [ str , Any ]) -> Dict [ str , Any ]: for key , val in data . items (): if key in self . keys : data [ key ] = self . transform ( val ) return data keys : List [ str ] class-attribute transform : Callable class-attribute __call__ ( data ) Source code in glasses/models/transform/transform.py 10 11 12 13 14 def __call__ ( self , data : Dict [ str , Any ]) -> Dict [ str , Any ]: for key , val in data . items (): if key in self . keys : data [ key ] = self . transform ( val ) return data","title":"transform"},{"location":"reference/models/transform/transform/#glasses.models.transform.transform.ApplyToKeys","text":"Source code in glasses/models/transform/transform.py 5 6 7 8 9 10 11 12 13 14 @dataclass class ApplyToKeys : transform : Callable keys : List [ str ] def __call__ ( self , data : Dict [ str , Any ]) -> Dict [ str , Any ]: for key , val in data . items (): if key in self . keys : data [ key ] = self . transform ( val ) return data","title":"ApplyToKeys"},{"location":"reference/models/transform/transform/#glasses.models.transform.transform.ApplyToKeys.keys","text":"","title":"keys"},{"location":"reference/models/transform/transform/#glasses.models.transform.transform.ApplyToKeys.transform","text":"","title":"transform"},{"location":"reference/models/transform/transform/#glasses.models.transform.transform.ApplyToKeys.__call__","text":"Source code in glasses/models/transform/transform.py 10 11 12 13 14 def __call__ ( self , data : Dict [ str , Any ]) -> Dict [ str , Any ]: for key , val in data . items (): if key in self . keys : data [ key ] = self . transform ( val ) return data","title":"__call__()"},{"location":"reference/models/vision/","text":"","title":"Index"},{"location":"reference/models/vision/auto/","text":"AutoModelBackbone Bases: AutoModel Source code in glasses/models/vision/auto.py 5 6 class AutoModelBackbone ( AutoModel ): names_to_configs = get_names_to_configs_map ( \"glasses.models.vision.backbones\" ) names_to_configs = get_names_to_configs_map ( 'glasses.models.vision.backbones' ) class-attribute AutoModelForImageClassification Bases: AutoModel Source code in glasses/models/vision/auto.py 9 10 11 12 class AutoModelForImageClassification ( AutoModel ): names_to_configs = get_names_to_configs_map ( \"glasses.models.vision.image.classification\" ) names_to_configs = get_names_to_configs_map ( 'glasses.models.vision.image.classification' ) class-attribute","title":"auto"},{"location":"reference/models/vision/auto/#glasses.models.vision.auto.AutoModelBackbone","text":"Bases: AutoModel Source code in glasses/models/vision/auto.py 5 6 class AutoModelBackbone ( AutoModel ): names_to_configs = get_names_to_configs_map ( \"glasses.models.vision.backbones\" )","title":"AutoModelBackbone"},{"location":"reference/models/vision/auto/#glasses.models.vision.auto.AutoModelBackbone.names_to_configs","text":"","title":"names_to_configs"},{"location":"reference/models/vision/auto/#glasses.models.vision.auto.AutoModelForImageClassification","text":"Bases: AutoModel Source code in glasses/models/vision/auto.py 9 10 11 12 class AutoModelForImageClassification ( AutoModel ): names_to_configs = get_names_to_configs_map ( \"glasses.models.vision.image.classification\" )","title":"AutoModelForImageClassification"},{"location":"reference/models/vision/auto/#glasses.models.vision.auto.AutoModelForImageClassification.names_to_configs","text":"","title":"names_to_configs"},{"location":"reference/models/vision/backbones/","text":"","title":"Index"},{"location":"reference/models/vision/backbones/base/","text":"Backbone Bases: nn . Module Source code in glasses/models/vision/backbones/base.py 6 7 8 class Backbone ( nn . Module ): def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: raise NotImplemented forward ( pixel_values ) Source code in glasses/models/vision/backbones/base.py 7 8 def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: raise NotImplemented","title":"base"},{"location":"reference/models/vision/backbones/base/#glasses.models.vision.backbones.base.Backbone","text":"Bases: nn . Module Source code in glasses/models/vision/backbones/base.py 6 7 8 class Backbone ( nn . Module ): def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: raise NotImplemented","title":"Backbone"},{"location":"reference/models/vision/backbones/base/#glasses.models.vision.backbones.base.Backbone.forward","text":"Source code in glasses/models/vision/backbones/base.py 7 8 def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: raise NotImplemented","title":"forward()"},{"location":"reference/models/vision/backbones/vit/","text":"","title":"Index"},{"location":"reference/models/vision/backbones/vit/config/","text":"ViTBackboneConfig dataclass Bases: Config Source code in glasses/models/vision/backbones/vit/config.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @dataclass class ViTBackboneConfig ( Config ): img_size : int = 224 in_channels : int = 3 patch_size : int = 16 depth : int = 12 embed_dim : int = 768 num_heads : int = 12 attn_drop_p : float = 0.0 projection_drop_p : float = 0.2 qkv_bias : bool = False forward_expansion : int = 4 forward_drop_p : float = 0.2 activation : nn . Module = nn . GELU def build ( self ) -> ViTBackbone : return ViTBackbone ( ** self . __dict__ ) activation : nn . Module = nn . GELU class-attribute attn_drop_p : float = 0.0 class-attribute depth : int = 12 class-attribute embed_dim : int = 768 class-attribute forward_drop_p : float = 0.2 class-attribute forward_expansion : int = 4 class-attribute img_size : int = 224 class-attribute in_channels : int = 3 class-attribute num_heads : int = 12 class-attribute patch_size : int = 16 class-attribute projection_drop_p : float = 0.2 class-attribute qkv_bias : bool = False class-attribute build () Source code in glasses/models/vision/backbones/vit/config.py 25 26 def build ( self ) -> ViTBackbone : return ViTBackbone ( ** self . __dict__ )","title":"config"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig","text":"Bases: Config Source code in glasses/models/vision/backbones/vit/config.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @dataclass class ViTBackboneConfig ( Config ): img_size : int = 224 in_channels : int = 3 patch_size : int = 16 depth : int = 12 embed_dim : int = 768 num_heads : int = 12 attn_drop_p : float = 0.0 projection_drop_p : float = 0.2 qkv_bias : bool = False forward_expansion : int = 4 forward_drop_p : float = 0.2 activation : nn . Module = nn . GELU def build ( self ) -> ViTBackbone : return ViTBackbone ( ** self . __dict__ )","title":"ViTBackboneConfig"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.activation","text":"","title":"activation"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.attn_drop_p","text":"","title":"attn_drop_p"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.depth","text":"","title":"depth"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.embed_dim","text":"","title":"embed_dim"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.forward_drop_p","text":"","title":"forward_drop_p"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.forward_expansion","text":"","title":"forward_expansion"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.img_size","text":"","title":"img_size"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.in_channels","text":"","title":"in_channels"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.num_heads","text":"","title":"num_heads"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.patch_size","text":"","title":"patch_size"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.projection_drop_p","text":"","title":"projection_drop_p"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.qkv_bias","text":"","title":"qkv_bias"},{"location":"reference/models/vision/backbones/vit/config/#glasses.models.vision.backbones.vit.config.ViTBackboneConfig.build","text":"Source code in glasses/models/vision/backbones/vit/config.py 25 26 def build ( self ) -> ViTBackbone : return ViTBackbone ( ** self . __dict__ )","title":"build()"},{"location":"reference/models/vision/backbones/vit/model/","text":"ResidualAddition Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 117 118 119 120 121 122 123 124 125 class ResidualAddition ( nn . Module ): def __init__ ( self , fn ): super () . __init__ () self . fn = fn def forward ( self , x , ** kwargs ): out = self . fn ( x , ** kwargs ) x = x + out return x fn = fn instance-attribute __init__ ( fn ) Source code in glasses/models/vision/backbones/vit/model.py 118 119 120 def __init__ ( self , fn ): super () . __init__ () self . fn = fn forward ( x , ** kwargs ) Source code in glasses/models/vision/backbones/vit/model.py 122 123 124 125 def forward ( self , x , ** kwargs ): out = self . fn ( x , ** kwargs ) x = x + out return x ViTAttentionBlock Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 class ViTAttentionBlock ( nn . Module ): def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , ): super () . __init__ () self . embed_dim = embed_dim self . num_heads = num_heads # fuse the queries, keys and values in one matrix self . qkv = nn . Linear ( embed_dim , embed_dim * 3 , bias = qkv_bias ) self . att_drop = nn . Dropout ( attn_drop_p ) self . projection = nn . Sequential ( nn . Linear ( embed_dim , embed_dim ), nn . Dropout ( projection_drop_p ) ) self . scaling = ( self . embed_dim // num_heads ) ** - 0.5 def forward ( self , x : Tensor , mask : Tensor = None ) -> Tensor : # split keys, queries and values in num_heads qkv = rearrange ( self . qkv ( x ), \"b n (qkv h d) -> (qkv) b h n d\" , h = self . num_heads , qkv = 3 ) queries , keys , values = qkv [ 0 ], qkv [ 1 ], qkv [ 2 ] # dot product, Q V^T, here we don't transpose before, so this is why # the sum is made on the last index of K energy = torch . einsum ( \"bhij, bhkj -> bhik\" , queries , keys ) * self . scaling if mask is not None : fill_value = torch . finfo ( torch . float32 ) . min energy . mask_fill ( ~ mask , fill_value ) att = F . softmax ( energy , dim =- 1 ) att = self . att_drop ( att ) # dot product out = torch . einsum ( \"bhij, bhjk -> bhik \" , att , values ) out = rearrange ( out , \"b h n d -> b n (h d)\" ) out = self . projection ( out ) return out att_drop = nn . Dropout ( attn_drop_p ) instance-attribute embed_dim = embed_dim instance-attribute num_heads = num_heads instance-attribute projection = nn . Sequential ( nn . Linear ( embed_dim , embed_dim ), nn . Dropout ( projection_drop_p )) instance-attribute qkv = nn . Linear ( embed_dim , embed_dim * 3 , bias = qkv_bias ) instance-attribute scaling = self . embed_dim // num_heads ** - 0.5 instance-attribute __init__ ( embed_dim = 768 , num_heads = 12 , attn_drop_p = 0.0 , projection_drop_p = 0.2 , qkv_bias = False ) Source code in glasses/models/vision/backbones/vit/model.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , ): super () . __init__ () self . embed_dim = embed_dim self . num_heads = num_heads # fuse the queries, keys and values in one matrix self . qkv = nn . Linear ( embed_dim , embed_dim * 3 , bias = qkv_bias ) self . att_drop = nn . Dropout ( attn_drop_p ) self . projection = nn . Sequential ( nn . Linear ( embed_dim , embed_dim ), nn . Dropout ( projection_drop_p ) ) self . scaling = ( self . embed_dim // num_heads ) ** - 0.5 forward ( x , mask = None ) Source code in glasses/models/vision/backbones/vit/model.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def forward ( self , x : Tensor , mask : Tensor = None ) -> Tensor : # split keys, queries and values in num_heads qkv = rearrange ( self . qkv ( x ), \"b n (qkv h d) -> (qkv) b h n d\" , h = self . num_heads , qkv = 3 ) queries , keys , values = qkv [ 0 ], qkv [ 1 ], qkv [ 2 ] # dot product, Q V^T, here we don't transpose before, so this is why # the sum is made on the last index of K energy = torch . einsum ( \"bhij, bhkj -> bhik\" , queries , keys ) * self . scaling if mask is not None : fill_value = torch . finfo ( torch . float32 ) . min energy . mask_fill ( ~ mask , fill_value ) att = F . softmax ( energy , dim =- 1 ) att = self . att_drop ( att ) # dot product out = torch . einsum ( \"bhij, bhjk -> bhik \" , att , values ) out = rearrange ( out , \"b h n d -> b n (h d)\" ) out = self . projection ( out ) return out ViTBackbone Bases: Backbone Source code in glasses/models/vision/backbones/vit/model.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 class ViTBackbone ( Backbone ): def __init__ ( self , img_size : int = 224 , in_channels : int = 3 , patch_size : int = 16 , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . embedder = ViTPatchEmbedding ( in_channels = in_channels , patch_size = patch_size , embed_dim = embed_dim , img_size = img_size , ) self . encoder = ViTEncoder ( depth = depth , embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , ) def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: embeddings = self . embedder ( pixel_values ) features = self . encoder ( embeddings ) return features embedder = ViTPatchEmbedding ( in_channels = in_channels , patch_size = patch_size , embed_dim = embed_dim , img_size = img_size ) instance-attribute encoder = ViTEncoder ( depth = depth , embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation ) instance-attribute __init__ ( img_size = 224 , in_channels = 3 , patch_size = 16 , depth = 12 , embed_dim = 768 , num_heads = 12 , attn_drop_p = 0.0 , projection_drop_p = 0.2 , qkv_bias = False , forward_expansion = 4 , forward_drop_p = 0.2 , activation = nn . GELU ) Source code in glasses/models/vision/backbones/vit/model.py 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 def __init__ ( self , img_size : int = 224 , in_channels : int = 3 , patch_size : int = 16 , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . embedder = ViTPatchEmbedding ( in_channels = in_channels , patch_size = patch_size , embed_dim = embed_dim , img_size = img_size , ) self . encoder = ViTEncoder ( depth = depth , embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , ) forward ( pixel_values ) Source code in glasses/models/vision/backbones/vit/model.py 245 246 247 248 def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: embeddings = self . embedder ( pixel_values ) features = self . encoder ( embeddings ) return features ViTBlock Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 class ViTBlock ( nn . Module ): def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . transformer = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTAttentionBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , ), ) ) self . mlp = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTMLPBlock ( embed_dim = embed_dim , expansion = forward_expansion , drop_p = forward_drop_p , activation = activation , ), ) ) def forward ( self , x ): x = self . transformer ( x ) x = self . mlp ( x ) return x mlp = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTMLPBlock ( embed_dim = embed_dim , expansion = forward_expansion , drop_p = forward_drop_p , activation = activation ))) instance-attribute transformer = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTAttentionBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias ))) instance-attribute __init__ ( embed_dim = 768 , num_heads = 12 , attn_drop_p = 0.0 , projection_drop_p = 0.2 , qkv_bias = False , forward_expansion = 4 , forward_drop_p = 0.2 , activation = nn . GELU ) Source code in glasses/models/vision/backbones/vit/model.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . transformer = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTAttentionBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , ), ) ) self . mlp = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTMLPBlock ( embed_dim = embed_dim , expansion = forward_expansion , drop_p = forward_drop_p , activation = activation , ), ) ) forward ( x ) Source code in glasses/models/vision/backbones/vit/model.py 165 166 167 168 def forward ( self , x ): x = self . transformer ( x ) x = self . mlp ( x ) return x ViTEncoder Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 class ViTEncoder ( nn . Module ): def __init__ ( self , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . layers = nn . ModuleList ( ViTBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , ) for _ in range ( depth ) ) self . norm = nn . LayerNorm ( embed_dim ) def forward ( self , x : Tensor ) -> Tensor : features = [] for layer in self . layers : features . append ( x ) x = layer ( x ) features . append ( self . norm ( x )) return features layers = nn . ModuleList ( ViTBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation ) for _ in range ( depth )) instance-attribute norm = nn . LayerNorm ( embed_dim ) instance-attribute __init__ ( depth = 12 , embed_dim = 768 , num_heads = 12 , attn_drop_p = 0.0 , projection_drop_p = 0.2 , qkv_bias = False , forward_expansion = 4 , forward_drop_p = 0.2 , activation = nn . GELU ) Source code in glasses/models/vision/backbones/vit/model.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 def __init__ ( self , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . layers = nn . ModuleList ( ViTBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , ) for _ in range ( depth ) ) self . norm = nn . LayerNorm ( embed_dim ) forward ( x ) Source code in glasses/models/vision/backbones/vit/model.py 200 201 202 203 204 205 206 def forward ( self , x : Tensor ) -> Tensor : features = [] for layer in self . layers : features . append ( x ) x = layer ( x ) features . append ( self . norm ( x )) return features ViTMLPBlock Bases: nn . Sequential Source code in glasses/models/vision/backbones/vit/model.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class ViTMLPBlock ( nn . Sequential ): def __init__ ( self , embed_dim : int , expansion : int = 4 , drop_p : float = 0.0 , activation : nn . Module = nn . GELU , ): super () . __init__ ( nn . Linear ( embed_dim , expansion * embed_dim ), activation (), nn . Dropout ( drop_p ), nn . Linear ( expansion * embed_dim , embed_dim ), nn . Dropout ( drop_p ), ) __init__ ( embed_dim , expansion = 4 , drop_p = 0.0 , activation = nn . GELU ) Source code in glasses/models/vision/backbones/vit/model.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def __init__ ( self , embed_dim : int , expansion : int = 4 , drop_p : float = 0.0 , activation : nn . Module = nn . GELU , ): super () . __init__ ( nn . Linear ( embed_dim , expansion * embed_dim ), activation (), nn . Dropout ( drop_p ), nn . Linear ( expansion * embed_dim , embed_dim ), nn . Dropout ( drop_p ), ) ViTPatchEmbedding Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 class ViTPatchEmbedding ( nn . Module ): def __init__ ( self , in_channels : int = 3 , patch_size : int = 16 , embed_dim : int = 768 , img_size : int = 224 , ): super () . __init__ () self . proj = nn . Sequential ( nn . Conv2d ( in_channels , embed_dim , kernel_size = patch_size , stride = patch_size ), Rearrange ( \"b e (h) (w) -> b (h w) e\" ), ) self . tokens = ViTTokens ( embed_dim ) self . positions = nn . Parameter ( torch . randn (( img_size // patch_size ) ** 2 + len ( self . tokens ), embed_dim ) ) def forward ( self , x : Tensor ) -> Tensor : x = self . proj ( x ) tokens = self . tokens ( x ) x = torch . cat ([ * tokens , x ], dim = 1 ) x = x + self . positions return x positions = nn . Parameter ( torch . randn ( img_size // patch_size ** 2 + len ( self . tokens ), embed_dim )) instance-attribute proj = nn . Sequential ( nn . Conv2d ( in_channels , embed_dim , kernel_size = patch_size , stride = patch_size ), Rearrange ( 'b e (h) (w) -> b (h w) e' )) instance-attribute tokens = ViTTokens ( embed_dim ) instance-attribute __init__ ( in_channels = 3 , patch_size = 16 , embed_dim = 768 , img_size = 224 ) Source code in glasses/models/vision/backbones/vit/model.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self , in_channels : int = 3 , patch_size : int = 16 , embed_dim : int = 768 , img_size : int = 224 , ): super () . __init__ () self . proj = nn . Sequential ( nn . Conv2d ( in_channels , embed_dim , kernel_size = patch_size , stride = patch_size ), Rearrange ( \"b e (h) (w) -> b (h w) e\" ), ) self . tokens = ViTTokens ( embed_dim ) self . positions = nn . Parameter ( torch . randn (( img_size // patch_size ) ** 2 + len ( self . tokens ), embed_dim ) ) forward ( x ) Source code in glasses/models/vision/backbones/vit/model.py 48 49 50 51 52 53 def forward ( self , x : Tensor ) -> Tensor : x = self . proj ( x ) tokens = self . tokens ( x ) x = torch . cat ([ * tokens , x ], dim = 1 ) x = x + self . positions return x ViTTokens Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class ViTTokens ( nn . Module ): def __init__ ( self , embed_dim : int ): super () . __init__ () self . cls_token = nn . Parameter ( torch . randn ( 1 , 1 , embed_dim )) def __len__ ( self ): return len ( list ( self . parameters ())) def forward ( self , x : Tensor ) -> List [ Tensor ]: b = x . shape [ 0 ] tokens = [] for token in self . parameters (): tokens . append ( repeat ( token , \"() n e -> b n e\" , b = b )) return tokens cls_token = nn . Parameter ( torch . randn ( 1 , 1 , embed_dim )) instance-attribute __init__ ( embed_dim ) Source code in glasses/models/vision/backbones/vit/model.py 13 14 15 def __init__ ( self , embed_dim : int ): super () . __init__ () self . cls_token = nn . Parameter ( torch . randn ( 1 , 1 , embed_dim )) __len__ () Source code in glasses/models/vision/backbones/vit/model.py 17 18 def __len__ ( self ): return len ( list ( self . parameters ())) forward ( x ) Source code in glasses/models/vision/backbones/vit/model.py 20 21 22 23 24 25 def forward ( self , x : Tensor ) -> List [ Tensor ]: b = x . shape [ 0 ] tokens = [] for token in self . parameters (): tokens . append ( repeat ( token , \"() n e -> b n e\" , b = b )) return tokens","title":"model"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ResidualAddition","text":"Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 117 118 119 120 121 122 123 124 125 class ResidualAddition ( nn . Module ): def __init__ ( self , fn ): super () . __init__ () self . fn = fn def forward ( self , x , ** kwargs ): out = self . fn ( x , ** kwargs ) x = x + out return x","title":"ResidualAddition"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ResidualAddition.fn","text":"","title":"fn"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ResidualAddition.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 118 119 120 def __init__ ( self , fn ): super () . __init__ () self . fn = fn","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ResidualAddition.forward","text":"Source code in glasses/models/vision/backbones/vit/model.py 122 123 124 125 def forward ( self , x , ** kwargs ): out = self . fn ( x , ** kwargs ) x = x + out return x","title":"forward()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock","text":"Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 class ViTAttentionBlock ( nn . Module ): def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , ): super () . __init__ () self . embed_dim = embed_dim self . num_heads = num_heads # fuse the queries, keys and values in one matrix self . qkv = nn . Linear ( embed_dim , embed_dim * 3 , bias = qkv_bias ) self . att_drop = nn . Dropout ( attn_drop_p ) self . projection = nn . Sequential ( nn . Linear ( embed_dim , embed_dim ), nn . Dropout ( projection_drop_p ) ) self . scaling = ( self . embed_dim // num_heads ) ** - 0.5 def forward ( self , x : Tensor , mask : Tensor = None ) -> Tensor : # split keys, queries and values in num_heads qkv = rearrange ( self . qkv ( x ), \"b n (qkv h d) -> (qkv) b h n d\" , h = self . num_heads , qkv = 3 ) queries , keys , values = qkv [ 0 ], qkv [ 1 ], qkv [ 2 ] # dot product, Q V^T, here we don't transpose before, so this is why # the sum is made on the last index of K energy = torch . einsum ( \"bhij, bhkj -> bhik\" , queries , keys ) * self . scaling if mask is not None : fill_value = torch . finfo ( torch . float32 ) . min energy . mask_fill ( ~ mask , fill_value ) att = F . softmax ( energy , dim =- 1 ) att = self . att_drop ( att ) # dot product out = torch . einsum ( \"bhij, bhjk -> bhik \" , att , values ) out = rearrange ( out , \"b h n d -> b n (h d)\" ) out = self . projection ( out ) return out","title":"ViTAttentionBlock"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.att_drop","text":"","title":"att_drop"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.embed_dim","text":"","title":"embed_dim"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.num_heads","text":"","title":"num_heads"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.projection","text":"","title":"projection"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.qkv","text":"","title":"qkv"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.scaling","text":"","title":"scaling"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , ): super () . __init__ () self . embed_dim = embed_dim self . num_heads = num_heads # fuse the queries, keys and values in one matrix self . qkv = nn . Linear ( embed_dim , embed_dim * 3 , bias = qkv_bias ) self . att_drop = nn . Dropout ( attn_drop_p ) self . projection = nn . Sequential ( nn . Linear ( embed_dim , embed_dim ), nn . Dropout ( projection_drop_p ) ) self . scaling = ( self . embed_dim // num_heads ) ** - 0.5","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTAttentionBlock.forward","text":"Source code in glasses/models/vision/backbones/vit/model.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def forward ( self , x : Tensor , mask : Tensor = None ) -> Tensor : # split keys, queries and values in num_heads qkv = rearrange ( self . qkv ( x ), \"b n (qkv h d) -> (qkv) b h n d\" , h = self . num_heads , qkv = 3 ) queries , keys , values = qkv [ 0 ], qkv [ 1 ], qkv [ 2 ] # dot product, Q V^T, here we don't transpose before, so this is why # the sum is made on the last index of K energy = torch . einsum ( \"bhij, bhkj -> bhik\" , queries , keys ) * self . scaling if mask is not None : fill_value = torch . finfo ( torch . float32 ) . min energy . mask_fill ( ~ mask , fill_value ) att = F . softmax ( energy , dim =- 1 ) att = self . att_drop ( att ) # dot product out = torch . einsum ( \"bhij, bhjk -> bhik \" , att , values ) out = rearrange ( out , \"b h n d -> b n (h d)\" ) out = self . projection ( out ) return out","title":"forward()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBackbone","text":"Bases: Backbone Source code in glasses/models/vision/backbones/vit/model.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 class ViTBackbone ( Backbone ): def __init__ ( self , img_size : int = 224 , in_channels : int = 3 , patch_size : int = 16 , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . embedder = ViTPatchEmbedding ( in_channels = in_channels , patch_size = patch_size , embed_dim = embed_dim , img_size = img_size , ) self . encoder = ViTEncoder ( depth = depth , embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , ) def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: embeddings = self . embedder ( pixel_values ) features = self . encoder ( embeddings ) return features","title":"ViTBackbone"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBackbone.embedder","text":"","title":"embedder"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBackbone.encoder","text":"","title":"encoder"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBackbone.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 def __init__ ( self , img_size : int = 224 , in_channels : int = 3 , patch_size : int = 16 , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . embedder = ViTPatchEmbedding ( in_channels = in_channels , patch_size = patch_size , embed_dim = embed_dim , img_size = img_size , ) self . encoder = ViTEncoder ( depth = depth , embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , )","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBackbone.forward","text":"Source code in glasses/models/vision/backbones/vit/model.py 245 246 247 248 def forward ( self , pixel_values : Tensor ) -> List [ Tensor ]: embeddings = self . embedder ( pixel_values ) features = self . encoder ( embeddings ) return features","title":"forward()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBlock","text":"Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 class ViTBlock ( nn . Module ): def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . transformer = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTAttentionBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , ), ) ) self . mlp = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTMLPBlock ( embed_dim = embed_dim , expansion = forward_expansion , drop_p = forward_drop_p , activation = activation , ), ) ) def forward ( self , x ): x = self . transformer ( x ) x = self . mlp ( x ) return x","title":"ViTBlock"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBlock.mlp","text":"","title":"mlp"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBlock.transformer","text":"","title":"transformer"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBlock.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def __init__ ( self , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . transformer = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTAttentionBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , ), ) ) self . mlp = ResidualAddition ( nn . Sequential ( nn . LayerNorm ( embed_dim ), ViTMLPBlock ( embed_dim = embed_dim , expansion = forward_expansion , drop_p = forward_drop_p , activation = activation , ), ) )","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTBlock.forward","text":"Source code in glasses/models/vision/backbones/vit/model.py 165 166 167 168 def forward ( self , x ): x = self . transformer ( x ) x = self . mlp ( x ) return x","title":"forward()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTEncoder","text":"Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 class ViTEncoder ( nn . Module ): def __init__ ( self , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . layers = nn . ModuleList ( ViTBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , ) for _ in range ( depth ) ) self . norm = nn . LayerNorm ( embed_dim ) def forward ( self , x : Tensor ) -> Tensor : features = [] for layer in self . layers : features . append ( x ) x = layer ( x ) features . append ( self . norm ( x )) return features","title":"ViTEncoder"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTEncoder.layers","text":"","title":"layers"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTEncoder.norm","text":"","title":"norm"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTEncoder.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 def __init__ ( self , depth : int = 12 , embed_dim : int = 768 , num_heads : int = 12 , attn_drop_p : float = 0.0 , projection_drop_p : float = 0.2 , qkv_bias : bool = False , forward_expansion : int = 4 , forward_drop_p : float = 0.2 , activation : nn . Module = nn . GELU , ): super () . __init__ () self . layers = nn . ModuleList ( ViTBlock ( embed_dim = embed_dim , num_heads = num_heads , attn_drop_p = attn_drop_p , projection_drop_p = projection_drop_p , qkv_bias = qkv_bias , forward_expansion = forward_expansion , forward_drop_p = forward_drop_p , activation = activation , ) for _ in range ( depth ) ) self . norm = nn . LayerNorm ( embed_dim )","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTEncoder.forward","text":"Source code in glasses/models/vision/backbones/vit/model.py 200 201 202 203 204 205 206 def forward ( self , x : Tensor ) -> Tensor : features = [] for layer in self . layers : features . append ( x ) x = layer ( x ) features . append ( self . norm ( x )) return features","title":"forward()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTMLPBlock","text":"Bases: nn . Sequential Source code in glasses/models/vision/backbones/vit/model.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class ViTMLPBlock ( nn . Sequential ): def __init__ ( self , embed_dim : int , expansion : int = 4 , drop_p : float = 0.0 , activation : nn . Module = nn . GELU , ): super () . __init__ ( nn . Linear ( embed_dim , expansion * embed_dim ), activation (), nn . Dropout ( drop_p ), nn . Linear ( expansion * embed_dim , embed_dim ), nn . Dropout ( drop_p ), )","title":"ViTMLPBlock"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTMLPBlock.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def __init__ ( self , embed_dim : int , expansion : int = 4 , drop_p : float = 0.0 , activation : nn . Module = nn . GELU , ): super () . __init__ ( nn . Linear ( embed_dim , expansion * embed_dim ), activation (), nn . Dropout ( drop_p ), nn . Linear ( expansion * embed_dim , embed_dim ), nn . Dropout ( drop_p ), )","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTPatchEmbedding","text":"Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 class ViTPatchEmbedding ( nn . Module ): def __init__ ( self , in_channels : int = 3 , patch_size : int = 16 , embed_dim : int = 768 , img_size : int = 224 , ): super () . __init__ () self . proj = nn . Sequential ( nn . Conv2d ( in_channels , embed_dim , kernel_size = patch_size , stride = patch_size ), Rearrange ( \"b e (h) (w) -> b (h w) e\" ), ) self . tokens = ViTTokens ( embed_dim ) self . positions = nn . Parameter ( torch . randn (( img_size // patch_size ) ** 2 + len ( self . tokens ), embed_dim ) ) def forward ( self , x : Tensor ) -> Tensor : x = self . proj ( x ) tokens = self . tokens ( x ) x = torch . cat ([ * tokens , x ], dim = 1 ) x = x + self . positions return x","title":"ViTPatchEmbedding"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTPatchEmbedding.positions","text":"","title":"positions"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTPatchEmbedding.proj","text":"","title":"proj"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTPatchEmbedding.tokens","text":"","title":"tokens"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTPatchEmbedding.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def __init__ ( self , in_channels : int = 3 , patch_size : int = 16 , embed_dim : int = 768 , img_size : int = 224 , ): super () . __init__ () self . proj = nn . Sequential ( nn . Conv2d ( in_channels , embed_dim , kernel_size = patch_size , stride = patch_size ), Rearrange ( \"b e (h) (w) -> b (h w) e\" ), ) self . tokens = ViTTokens ( embed_dim ) self . positions = nn . Parameter ( torch . randn (( img_size // patch_size ) ** 2 + len ( self . tokens ), embed_dim ) )","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTPatchEmbedding.forward","text":"Source code in glasses/models/vision/backbones/vit/model.py 48 49 50 51 52 53 def forward ( self , x : Tensor ) -> Tensor : x = self . proj ( x ) tokens = self . tokens ( x ) x = torch . cat ([ * tokens , x ], dim = 1 ) x = x + self . positions return x","title":"forward()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTTokens","text":"Bases: nn . Module Source code in glasses/models/vision/backbones/vit/model.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class ViTTokens ( nn . Module ): def __init__ ( self , embed_dim : int ): super () . __init__ () self . cls_token = nn . Parameter ( torch . randn ( 1 , 1 , embed_dim )) def __len__ ( self ): return len ( list ( self . parameters ())) def forward ( self , x : Tensor ) -> List [ Tensor ]: b = x . shape [ 0 ] tokens = [] for token in self . parameters (): tokens . append ( repeat ( token , \"() n e -> b n e\" , b = b )) return tokens","title":"ViTTokens"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTTokens.cls_token","text":"","title":"cls_token"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTTokens.__init__","text":"Source code in glasses/models/vision/backbones/vit/model.py 13 14 15 def __init__ ( self , embed_dim : int ): super () . __init__ () self . cls_token = nn . Parameter ( torch . randn ( 1 , 1 , embed_dim ))","title":"__init__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTTokens.__len__","text":"Source code in glasses/models/vision/backbones/vit/model.py 17 18 def __len__ ( self ): return len ( list ( self . parameters ()))","title":"__len__()"},{"location":"reference/models/vision/backbones/vit/model/#glasses.models.vision.backbones.vit.model.ViTTokens.forward","text":"Source code in glasses/models/vision/backbones/vit/model.py 20 21 22 23 24 25 def forward ( self , x : Tensor ) -> List [ Tensor ]: b = x . shape [ 0 ] tokens = [] for token in self . parameters (): tokens . append ( repeat ( token , \"() n e -> b n e\" , b = b )) return tokens","title":"forward()"},{"location":"reference/models/vision/backbones/vit/zoo/","text":"zoo = ModelZoo ( vit_small_patch16_224 = vit_small_patch16_224 , vit_base_patch16_224 = vit_base_patch16_224 , vit_base_patch16_384 = vit_base_patch16_384 ) module-attribute vit_base_patch16_224 () Source code in glasses/models/vision/backbones/vit/zoo.py 10 11 def vit_base_patch16_224 (): return ViTBackboneConfig ( depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True ) vit_base_patch16_384 () Source code in glasses/models/vision/backbones/vit/zoo.py 14 15 16 17 def vit_base_patch16_384 (): return ViTBackboneConfig ( img_size = 384 , depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True ) vit_small_patch16_224 () Source code in glasses/models/vision/backbones/vit/zoo.py 6 7 def vit_small_patch16_224 (): return ViTBackboneConfig ( depth = 8 , num_heads = 8 , forward_expansion = 3 )","title":"zoo"},{"location":"reference/models/vision/backbones/vit/zoo/#glasses.models.vision.backbones.vit.zoo.zoo","text":"","title":"zoo"},{"location":"reference/models/vision/backbones/vit/zoo/#glasses.models.vision.backbones.vit.zoo.vit_base_patch16_224","text":"Source code in glasses/models/vision/backbones/vit/zoo.py 10 11 def vit_base_patch16_224 (): return ViTBackboneConfig ( depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True )","title":"vit_base_patch16_224()"},{"location":"reference/models/vision/backbones/vit/zoo/#glasses.models.vision.backbones.vit.zoo.vit_base_patch16_384","text":"Source code in glasses/models/vision/backbones/vit/zoo.py 14 15 16 17 def vit_base_patch16_384 (): return ViTBackboneConfig ( img_size = 384 , depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True )","title":"vit_base_patch16_384()"},{"location":"reference/models/vision/backbones/vit/zoo/#glasses.models.vision.backbones.vit.zoo.vit_small_patch16_224","text":"Source code in glasses/models/vision/backbones/vit/zoo.py 6 7 def vit_small_patch16_224 (): return ViTBackboneConfig ( depth = 8 , num_heads = 8 , forward_expansion = 3 )","title":"vit_small_patch16_224()"},{"location":"reference/models/vision/image/","text":"","title":"Index"},{"location":"reference/models/vision/image/classification/","text":"","title":"Index"},{"location":"reference/models/vision/image/classification/base/","text":"ModelForImageClassification Bases: nn . Module Base class for classification models Define a custom image classification model. It can be anything you want, the only contrain is that it must return a ModelForImageClassificationOutput . class MyModelForImageClassification ( ModelForImageClassification ): def __init__ ( self , in_channels : int , num_classes : int ): super () . __init__ () self . conv = nn . Conv2d ( in_channels , 64 , kernel_size = 3 ) self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( 64 , num_classes ) def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : x = self . conv ( pixel_values ) x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return { \"logits\" : x } The above example is a fixed models, it doesn't have composable part. In reality, classification models are (usually) composed by a backbone and a head . Since all the backbones and heads in glasses must follow known rules, it trivial to compose them. from glasses.models.vision.backbones import ResNet class ResNetForImageClassification ( ModelForImageClassification ): def __init__ ( self , in_channels : int , ... , num_classes : int ): super () . __init__ () self . backbone = ResNet ( in_channels , .... ) self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( 64 , num_classes ) def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : features = self . backbone ( pixel_values ) x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return { \"logits\" : x } In 99% of cases you will take advantage of the AnyModelForImageClassification that allows you to mix on the fly any backbone and classification head in glasses. Source code in glasses/models/vision/image/classification/base.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class ModelForImageClassification ( nn . Module ): \"\"\"Base class for classification models Define a custom image classification model. It can be anything you want, the only contrain is that it **must** return a `ModelForImageClassificationOutput`. ```python class MyModelForImageClassification(ModelForImageClassification): def __init__(self, in_channels: int, num_classes: int ): super().__init__() self.conv = nn.Conv2d(in_channels, 64, kernel_size=3) self.pool = nn.AdaptiveAvgPool2d((1, 1)) self.flat = nn.Flatten() self.fc = nn.Linear(64, num_classes) def forward(self, pixel_values: Tensor) -> ModelForImageClassificationOutput: x = self.conv(pixel_values) x = self.pool(x) x = self.flat(x) x = self.fc(x) return {\"logits\": x} ``` The above example is a fixed models, it doesn't have composable part. In reality, classification models are (usually) composed by a **backbone** and a **head**. Since all the backbones and heads in glasses must follow known rules, it trivial to compose them. ```python from glasses.models.vision.backbones import ResNet class ResNetForImageClassification(ModelForImageClassification): def __init__(self, in_channels: int, ..., num_classes: int): super().__init__() self.backbone =ResNet(in_channels, ....) self.pool = nn.AdaptiveAvgPool2d((1, 1)) self.flat = nn.Flatten() self.fc = nn.Linear(64, num_classes) def forward(self, pixel_values: Tensor) -> ModelForImageClassificationOutput: features = self.backbone(pixel_values) x = features[-1] x = self.pool(x) x = self.flat(x) x = self.fc(x) return {\"logits\": x} ``` In 99% of cases you will take advantage of the [`AnyModelForImageClassification`]() that allows you to mix on the fly any backbone and classification head in glasses. \"\"\" def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : \"\"\"The forward method for classification head. Args: pixel_values (Tensor): The input image. Returns: Tensor: The logits. \"\"\" raise NotImplementedError forward ( pixel_values ) The forward method for classification head. Parameters: Name Type Description Default pixel_values Tensor The input image. required Returns: Name Type Description Tensor ModelForImageClassificationOutput The logits. Source code in glasses/models/vision/image/classification/base.py 59 60 61 62 63 64 65 66 67 68 def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : \"\"\"The forward method for classification head. Args: pixel_values (Tensor): The input image. Returns: Tensor: The logits. \"\"\" raise NotImplementedError","title":"base"},{"location":"reference/models/vision/image/classification/base/#glasses.models.vision.image.classification.base.ModelForImageClassification","text":"Bases: nn . Module Base class for classification models Define a custom image classification model. It can be anything you want, the only contrain is that it must return a ModelForImageClassificationOutput . class MyModelForImageClassification ( ModelForImageClassification ): def __init__ ( self , in_channels : int , num_classes : int ): super () . __init__ () self . conv = nn . Conv2d ( in_channels , 64 , kernel_size = 3 ) self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( 64 , num_classes ) def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : x = self . conv ( pixel_values ) x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return { \"logits\" : x } The above example is a fixed models, it doesn't have composable part. In reality, classification models are (usually) composed by a backbone and a head . Since all the backbones and heads in glasses must follow known rules, it trivial to compose them. from glasses.models.vision.backbones import ResNet class ResNetForImageClassification ( ModelForImageClassification ): def __init__ ( self , in_channels : int , ... , num_classes : int ): super () . __init__ () self . backbone = ResNet ( in_channels , .... ) self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( 64 , num_classes ) def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : features = self . backbone ( pixel_values ) x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return { \"logits\" : x } In 99% of cases you will take advantage of the AnyModelForImageClassification that allows you to mix on the fly any backbone and classification head in glasses. Source code in glasses/models/vision/image/classification/base.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class ModelForImageClassification ( nn . Module ): \"\"\"Base class for classification models Define a custom image classification model. It can be anything you want, the only contrain is that it **must** return a `ModelForImageClassificationOutput`. ```python class MyModelForImageClassification(ModelForImageClassification): def __init__(self, in_channels: int, num_classes: int ): super().__init__() self.conv = nn.Conv2d(in_channels, 64, kernel_size=3) self.pool = nn.AdaptiveAvgPool2d((1, 1)) self.flat = nn.Flatten() self.fc = nn.Linear(64, num_classes) def forward(self, pixel_values: Tensor) -> ModelForImageClassificationOutput: x = self.conv(pixel_values) x = self.pool(x) x = self.flat(x) x = self.fc(x) return {\"logits\": x} ``` The above example is a fixed models, it doesn't have composable part. In reality, classification models are (usually) composed by a **backbone** and a **head**. Since all the backbones and heads in glasses must follow known rules, it trivial to compose them. ```python from glasses.models.vision.backbones import ResNet class ResNetForImageClassification(ModelForImageClassification): def __init__(self, in_channels: int, ..., num_classes: int): super().__init__() self.backbone =ResNet(in_channels, ....) self.pool = nn.AdaptiveAvgPool2d((1, 1)) self.flat = nn.Flatten() self.fc = nn.Linear(64, num_classes) def forward(self, pixel_values: Tensor) -> ModelForImageClassificationOutput: features = self.backbone(pixel_values) x = features[-1] x = self.pool(x) x = self.flat(x) x = self.fc(x) return {\"logits\": x} ``` In 99% of cases you will take advantage of the [`AnyModelForImageClassification`]() that allows you to mix on the fly any backbone and classification head in glasses. \"\"\" def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : \"\"\"The forward method for classification head. Args: pixel_values (Tensor): The input image. Returns: Tensor: The logits. \"\"\" raise NotImplementedError","title":"ModelForImageClassification"},{"location":"reference/models/vision/image/classification/base/#glasses.models.vision.image.classification.base.ModelForImageClassification.forward","text":"The forward method for classification head. Parameters: Name Type Description Default pixel_values Tensor The input image. required Returns: Name Type Description Tensor ModelForImageClassificationOutput The logits. Source code in glasses/models/vision/image/classification/base.py 59 60 61 62 63 64 65 66 67 68 def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : \"\"\"The forward method for classification head. Args: pixel_values (Tensor): The input image. Returns: Tensor: The logits. \"\"\" raise NotImplementedError","title":"forward()"},{"location":"reference/models/vision/image/classification/outputs/","text":"ModelForImageClassificationOutput Bases: TypedDict The output for image classification models. Source code in glasses/models/vision/image/classification/outputs.py 6 7 8 9 class ModelForImageClassificationOutput ( TypedDict ): \"\"\"The output for image classification models.\"\"\" logits : Tensor logits : Tensor class-attribute","title":"outputs"},{"location":"reference/models/vision/image/classification/outputs/#glasses.models.vision.image.classification.outputs.ModelForImageClassificationOutput","text":"Bases: TypedDict The output for image classification models. Source code in glasses/models/vision/image/classification/outputs.py 6 7 8 9 class ModelForImageClassificationOutput ( TypedDict ): \"\"\"The output for image classification models.\"\"\" logits : Tensor","title":"ModelForImageClassificationOutput"},{"location":"reference/models/vision/image/classification/outputs/#glasses.models.vision.image.classification.outputs.ModelForImageClassificationOutput.logits","text":"","title":"logits"},{"location":"reference/models/vision/image/classification/common/","text":"","title":"Index"},{"location":"reference/models/vision/image/classification/common/config/","text":"AnyModelForImageClassificationConfig dataclass Bases: Config Source code in glasses/models/vision/image/classification/common/config.py 8 9 10 11 12 13 14 15 16 @dataclass class AnyModelForImageClassificationConfig ( Config ): backbone_config : Config head_config : Config def build ( self ) -> AnyModelForImageClassification : backbone = self . backbone_config . build () head = self . head_config . build () return AnyModelForImageClassification ( backbone , head ) backbone_config : Config class-attribute head_config : Config class-attribute build () Source code in glasses/models/vision/image/classification/common/config.py 13 14 15 16 def build ( self ) -> AnyModelForImageClassification : backbone = self . backbone_config . build () head = self . head_config . build () return AnyModelForImageClassification ( backbone , head )","title":"config"},{"location":"reference/models/vision/image/classification/common/config/#glasses.models.vision.image.classification.common.config.AnyModelForImageClassificationConfig","text":"Bases: Config Source code in glasses/models/vision/image/classification/common/config.py 8 9 10 11 12 13 14 15 16 @dataclass class AnyModelForImageClassificationConfig ( Config ): backbone_config : Config head_config : Config def build ( self ) -> AnyModelForImageClassification : backbone = self . backbone_config . build () head = self . head_config . build () return AnyModelForImageClassification ( backbone , head )","title":"AnyModelForImageClassificationConfig"},{"location":"reference/models/vision/image/classification/common/config/#glasses.models.vision.image.classification.common.config.AnyModelForImageClassificationConfig.backbone_config","text":"","title":"backbone_config"},{"location":"reference/models/vision/image/classification/common/config/#glasses.models.vision.image.classification.common.config.AnyModelForImageClassificationConfig.head_config","text":"","title":"head_config"},{"location":"reference/models/vision/image/classification/common/config/#glasses.models.vision.image.classification.common.config.AnyModelForImageClassificationConfig.build","text":"Source code in glasses/models/vision/image/classification/common/config.py 13 14 15 16 def build ( self ) -> AnyModelForImageClassification : backbone = self . backbone_config . build () head = self . head_config . build () return AnyModelForImageClassification ( backbone , head )","title":"build()"},{"location":"reference/models/vision/image/classification/common/model/","text":"AnyModelForImageClassification Bases: ModelForImageClassification Source code in glasses/models/vision/image/classification/common/model.py 11 12 13 14 15 16 17 18 19 20 class AnyModelForImageClassification ( ModelForImageClassification ): def __init__ ( self , backbone : nn . Module , head : nn . Module ): super () . __init__ () self . backbone = backbone self . head = head def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : features : List [ Tensor ] = self . backbone ( pixel_values ) logits : Tensor = self . head ( features ) return { \"logits\" : logits } backbone = backbone instance-attribute head = head instance-attribute __init__ ( backbone , head ) Source code in glasses/models/vision/image/classification/common/model.py 12 13 14 15 def __init__ ( self , backbone : nn . Module , head : nn . Module ): super () . __init__ () self . backbone = backbone self . head = head forward ( pixel_values ) Source code in glasses/models/vision/image/classification/common/model.py 17 18 19 20 def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : features : List [ Tensor ] = self . backbone ( pixel_values ) logits : Tensor = self . head ( features ) return { \"logits\" : logits }","title":"model"},{"location":"reference/models/vision/image/classification/common/model/#glasses.models.vision.image.classification.common.model.AnyModelForImageClassification","text":"Bases: ModelForImageClassification Source code in glasses/models/vision/image/classification/common/model.py 11 12 13 14 15 16 17 18 19 20 class AnyModelForImageClassification ( ModelForImageClassification ): def __init__ ( self , backbone : nn . Module , head : nn . Module ): super () . __init__ () self . backbone = backbone self . head = head def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : features : List [ Tensor ] = self . backbone ( pixel_values ) logits : Tensor = self . head ( features ) return { \"logits\" : logits }","title":"AnyModelForImageClassification"},{"location":"reference/models/vision/image/classification/common/model/#glasses.models.vision.image.classification.common.model.AnyModelForImageClassification.backbone","text":"","title":"backbone"},{"location":"reference/models/vision/image/classification/common/model/#glasses.models.vision.image.classification.common.model.AnyModelForImageClassification.head","text":"","title":"head"},{"location":"reference/models/vision/image/classification/common/model/#glasses.models.vision.image.classification.common.model.AnyModelForImageClassification.__init__","text":"Source code in glasses/models/vision/image/classification/common/model.py 12 13 14 15 def __init__ ( self , backbone : nn . Module , head : nn . Module ): super () . __init__ () self . backbone = backbone self . head = head","title":"__init__()"},{"location":"reference/models/vision/image/classification/common/model/#glasses.models.vision.image.classification.common.model.AnyModelForImageClassification.forward","text":"Source code in glasses/models/vision/image/classification/common/model.py 17 18 19 20 def forward ( self , pixel_values : Tensor ) -> ModelForImageClassificationOutput : features : List [ Tensor ] = self . backbone ( pixel_values ) logits : Tensor = self . head ( features ) return { \"logits\" : logits }","title":"forward()"},{"location":"reference/models/vision/image/classification/heads/","text":"","title":"Index"},{"location":"reference/models/vision/image/classification/heads/base/","text":"HeadForImageClassification Bases: nn . Module Base class for classification heads Define a custom classification head class LinearHead ( HeadForImageClassification ): def __init__ ( self , num_classes : int , in_channels : int ): super () . __init__ () self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( in_channels , num_classes ) def forward ( self , features : List [ Tensor ]) -> Tensor : x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return x Source code in glasses/models/vision/image/classification/heads/base.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class HeadForImageClassification ( nn . Module ): \"\"\"Base class for classification heads Define a custom classification head ```python class LinearHead(HeadForImageClassification): def __init__(self, num_classes: int, in_channels: int): super().__init__() self.pool = nn.AdaptiveAvgPool2d((1, 1)) self.flat = nn.Flatten() self.fc = nn.Linear(in_channels, num_classes) def forward(self, features: List[Tensor]) -> Tensor: x = features[-1] x = self.pool(x) x = self.flat(x) x = self.fc(x) return x ``` \"\"\" def forward ( self , features : List [ Tensor ]) -> Tensor : \"\"\"The forward method for classification head. Args: features (List[Tensor]): A list of features. Returns: Tensor: The logits \"\"\" raise NotImplementedError forward ( features ) The forward method for classification head. Parameters: Name Type Description Default features List [ Tensor ] A list of features. required Returns: Name Type Description Tensor Tensor The logits Source code in glasses/models/vision/image/classification/heads/base.py 30 31 32 33 34 35 36 37 38 39 def forward ( self , features : List [ Tensor ]) -> Tensor : \"\"\"The forward method for classification head. Args: features (List[Tensor]): A list of features. Returns: Tensor: The logits \"\"\" raise NotImplementedError","title":"base"},{"location":"reference/models/vision/image/classification/heads/base/#glasses.models.vision.image.classification.heads.base.HeadForImageClassification","text":"Bases: nn . Module Base class for classification heads Define a custom classification head class LinearHead ( HeadForImageClassification ): def __init__ ( self , num_classes : int , in_channels : int ): super () . __init__ () self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( in_channels , num_classes ) def forward ( self , features : List [ Tensor ]) -> Tensor : x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return x Source code in glasses/models/vision/image/classification/heads/base.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class HeadForImageClassification ( nn . Module ): \"\"\"Base class for classification heads Define a custom classification head ```python class LinearHead(HeadForImageClassification): def __init__(self, num_classes: int, in_channels: int): super().__init__() self.pool = nn.AdaptiveAvgPool2d((1, 1)) self.flat = nn.Flatten() self.fc = nn.Linear(in_channels, num_classes) def forward(self, features: List[Tensor]) -> Tensor: x = features[-1] x = self.pool(x) x = self.flat(x) x = self.fc(x) return x ``` \"\"\" def forward ( self , features : List [ Tensor ]) -> Tensor : \"\"\"The forward method for classification head. Args: features (List[Tensor]): A list of features. Returns: Tensor: The logits \"\"\" raise NotImplementedError","title":"HeadForImageClassification"},{"location":"reference/models/vision/image/classification/heads/base/#glasses.models.vision.image.classification.heads.base.HeadForImageClassification.forward","text":"The forward method for classification head. Parameters: Name Type Description Default features List [ Tensor ] A list of features. required Returns: Name Type Description Tensor Tensor The logits Source code in glasses/models/vision/image/classification/heads/base.py 30 31 32 33 34 35 36 37 38 39 def forward ( self , features : List [ Tensor ]) -> Tensor : \"\"\"The forward method for classification head. Args: features (List[Tensor]): A list of features. Returns: Tensor: The logits \"\"\" raise NotImplementedError","title":"forward()"},{"location":"reference/models/vision/image/classification/heads/linear_head/","text":"","title":"Index"},{"location":"reference/models/vision/image/classification/heads/linear_head/config/","text":"LinearHeadConfig dataclass Bases: Config Source code in glasses/models/vision/image/classification/heads/linear_head/config.py 8 9 10 11 12 13 14 @dataclass class LinearHeadConfig ( Config ): in_channels : int num_classes : int def build ( self ) -> LinearHead : return LinearHead ( ** self . __dict__ ) in_channels : int class-attribute num_classes : int class-attribute build () Source code in glasses/models/vision/image/classification/heads/linear_head/config.py 13 14 def build ( self ) -> LinearHead : return LinearHead ( ** self . __dict__ )","title":"config"},{"location":"reference/models/vision/image/classification/heads/linear_head/config/#glasses.models.vision.image.classification.heads.linear_head.config.LinearHeadConfig","text":"Bases: Config Source code in glasses/models/vision/image/classification/heads/linear_head/config.py 8 9 10 11 12 13 14 @dataclass class LinearHeadConfig ( Config ): in_channels : int num_classes : int def build ( self ) -> LinearHead : return LinearHead ( ** self . __dict__ )","title":"LinearHeadConfig"},{"location":"reference/models/vision/image/classification/heads/linear_head/config/#glasses.models.vision.image.classification.heads.linear_head.config.LinearHeadConfig.in_channels","text":"","title":"in_channels"},{"location":"reference/models/vision/image/classification/heads/linear_head/config/#glasses.models.vision.image.classification.heads.linear_head.config.LinearHeadConfig.num_classes","text":"","title":"num_classes"},{"location":"reference/models/vision/image/classification/heads/linear_head/config/#glasses.models.vision.image.classification.heads.linear_head.config.LinearHeadConfig.build","text":"Source code in glasses/models/vision/image/classification/heads/linear_head/config.py 13 14 def build ( self ) -> LinearHead : return LinearHead ( ** self . __dict__ )","title":"build()"},{"location":"reference/models/vision/image/classification/heads/linear_head/model/","text":"LinearHead Bases: HeadForImageClassification Source code in glasses/models/vision/image/classification/heads/linear_head/model.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class LinearHead ( HeadForImageClassification ): def __init__ ( self , in_channels : int , num_classes : int , ): super () . __init__ () self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( in_channels , num_classes ) def forward ( self , features : List [ Tensor ]) -> Tensor : x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return x fc = nn . Linear ( in_channels , num_classes ) instance-attribute flat = nn . Flatten () instance-attribute pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) instance-attribute __init__ ( in_channels , num_classes ) Source code in glasses/models/vision/image/classification/heads/linear_head/model.py 9 10 11 12 13 14 15 16 17 def __init__ ( self , in_channels : int , num_classes : int , ): super () . __init__ () self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( in_channels , num_classes ) forward ( features ) Source code in glasses/models/vision/image/classification/heads/linear_head/model.py 19 20 21 22 23 24 def forward ( self , features : List [ Tensor ]) -> Tensor : x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return x","title":"model"},{"location":"reference/models/vision/image/classification/heads/linear_head/model/#glasses.models.vision.image.classification.heads.linear_head.model.LinearHead","text":"Bases: HeadForImageClassification Source code in glasses/models/vision/image/classification/heads/linear_head/model.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class LinearHead ( HeadForImageClassification ): def __init__ ( self , in_channels : int , num_classes : int , ): super () . __init__ () self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( in_channels , num_classes ) def forward ( self , features : List [ Tensor ]) -> Tensor : x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return x","title":"LinearHead"},{"location":"reference/models/vision/image/classification/heads/linear_head/model/#glasses.models.vision.image.classification.heads.linear_head.model.LinearHead.fc","text":"","title":"fc"},{"location":"reference/models/vision/image/classification/heads/linear_head/model/#glasses.models.vision.image.classification.heads.linear_head.model.LinearHead.flat","text":"","title":"flat"},{"location":"reference/models/vision/image/classification/heads/linear_head/model/#glasses.models.vision.image.classification.heads.linear_head.model.LinearHead.pool","text":"","title":"pool"},{"location":"reference/models/vision/image/classification/heads/linear_head/model/#glasses.models.vision.image.classification.heads.linear_head.model.LinearHead.__init__","text":"Source code in glasses/models/vision/image/classification/heads/linear_head/model.py 9 10 11 12 13 14 15 16 17 def __init__ ( self , in_channels : int , num_classes : int , ): super () . __init__ () self . pool = nn . AdaptiveAvgPool2d (( 1 , 1 )) self . flat = nn . Flatten () self . fc = nn . Linear ( in_channels , num_classes )","title":"__init__()"},{"location":"reference/models/vision/image/classification/heads/linear_head/model/#glasses.models.vision.image.classification.heads.linear_head.model.LinearHead.forward","text":"Source code in glasses/models/vision/image/classification/heads/linear_head/model.py 19 20 21 22 23 24 def forward ( self , features : List [ Tensor ]) -> Tensor : x = features [ - 1 ] x = self . pool ( x ) x = self . flat ( x ) x = self . fc ( x ) return x","title":"forward()"},{"location":"reference/models/vision/image/classification/heads/vit/","text":"","title":"Index"},{"location":"reference/models/vision/image/classification/heads/vit/config/","text":"ViTHeadConfig dataclass Bases: Config Source code in glasses/models/vision/image/classification/heads/vit/config.py 8 9 10 11 12 13 14 15 @dataclass class ViTHeadConfig ( Config ): emb_size : int = 768 num_classes : int = 1000 policy : str = \"token\" def build ( self ) -> ViTHead : return ViTHead ( ** self . __dict__ ) emb_size : int = 768 class-attribute num_classes : int = 1000 class-attribute policy : str = 'token' class-attribute build () Source code in glasses/models/vision/image/classification/heads/vit/config.py 14 15 def build ( self ) -> ViTHead : return ViTHead ( ** self . __dict__ )","title":"config"},{"location":"reference/models/vision/image/classification/heads/vit/config/#glasses.models.vision.image.classification.heads.vit.config.ViTHeadConfig","text":"Bases: Config Source code in glasses/models/vision/image/classification/heads/vit/config.py 8 9 10 11 12 13 14 15 @dataclass class ViTHeadConfig ( Config ): emb_size : int = 768 num_classes : int = 1000 policy : str = \"token\" def build ( self ) -> ViTHead : return ViTHead ( ** self . __dict__ )","title":"ViTHeadConfig"},{"location":"reference/models/vision/image/classification/heads/vit/config/#glasses.models.vision.image.classification.heads.vit.config.ViTHeadConfig.emb_size","text":"","title":"emb_size"},{"location":"reference/models/vision/image/classification/heads/vit/config/#glasses.models.vision.image.classification.heads.vit.config.ViTHeadConfig.num_classes","text":"","title":"num_classes"},{"location":"reference/models/vision/image/classification/heads/vit/config/#glasses.models.vision.image.classification.heads.vit.config.ViTHeadConfig.policy","text":"","title":"policy"},{"location":"reference/models/vision/image/classification/heads/vit/config/#glasses.models.vision.image.classification.heads.vit.config.ViTHeadConfig.build","text":"Source code in glasses/models/vision/image/classification/heads/vit/config.py 14 15 def build ( self ) -> ViTHead : return ViTHead ( ** self . __dict__ )","title":"build()"},{"location":"reference/models/vision/image/classification/heads/vit/model/","text":"ViTHead Bases: HeadForImageClassification Source code in glasses/models/vision/image/classification/heads/vit/model.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class ViTHead ( HeadForImageClassification ): POLICIES = [ \"token\" , \"mean\" ] def __init__ ( self , emb_size : int = 768 , num_classes : int = 1000 , policy : str = \"token\" ): \"\"\" ViT Classification Head Args: emb_size (int, optional): Embedding dimensions Defaults to 768. num_classes (int, optional): [description]. Defaults to 1000. policy (str, optional): Pooling policy, can be token or mean. Defaults to 'token'. \"\"\" if policy not in self . POLICIES : raise ValueError ( f \"Only policies { ',' . join ( self . POLICIES ) } are supported\" ) super () . __init__ () self . pool = ( Reduce ( \"b n e -> b e\" , reduction = \"mean\" ) if policy == \"mean\" else Lambda ( lambda x : x [:, 0 ]) ) self . fc = nn . Linear ( emb_size , num_classes ) def forward ( self , features : List [ Tensor ]) -> Tensor : x = self . pool ( features [ - 1 ]) x = self . fc ( x ) return x POLICIES = [ 'token' , 'mean' ] class-attribute fc = nn . Linear ( emb_size , num_classes ) instance-attribute pool = Reduce ( 'b n e -> b e' , reduction = 'mean' ) if policy == 'mean' else Lambda ( lambda x : x [:, 0 ]) instance-attribute __init__ ( emb_size = 768 , num_classes = 1000 , policy = 'token' ) ViT Classification Head Parameters: Name Type Description Default emb_size int Embedding dimensions Defaults to 768. 768 num_classes int [description]. Defaults to 1000. 1000 policy str Pooling policy, can be token or mean. Defaults to 'token'. 'token' Source code in glasses/models/vision/image/classification/heads/vit/model.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , emb_size : int = 768 , num_classes : int = 1000 , policy : str = \"token\" ): \"\"\" ViT Classification Head Args: emb_size (int, optional): Embedding dimensions Defaults to 768. num_classes (int, optional): [description]. Defaults to 1000. policy (str, optional): Pooling policy, can be token or mean. Defaults to 'token'. \"\"\" if policy not in self . POLICIES : raise ValueError ( f \"Only policies { ',' . join ( self . POLICIES ) } are supported\" ) super () . __init__ () self . pool = ( Reduce ( \"b n e -> b e\" , reduction = \"mean\" ) if policy == \"mean\" else Lambda ( lambda x : x [:, 0 ]) ) self . fc = nn . Linear ( emb_size , num_classes ) forward ( features ) Source code in glasses/models/vision/image/classification/heads/vit/model.py 35 36 37 38 def forward ( self , features : List [ Tensor ]) -> Tensor : x = self . pool ( features [ - 1 ]) x = self . fc ( x ) return x","title":"model"},{"location":"reference/models/vision/image/classification/heads/vit/model/#glasses.models.vision.image.classification.heads.vit.model.ViTHead","text":"Bases: HeadForImageClassification Source code in glasses/models/vision/image/classification/heads/vit/model.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class ViTHead ( HeadForImageClassification ): POLICIES = [ \"token\" , \"mean\" ] def __init__ ( self , emb_size : int = 768 , num_classes : int = 1000 , policy : str = \"token\" ): \"\"\" ViT Classification Head Args: emb_size (int, optional): Embedding dimensions Defaults to 768. num_classes (int, optional): [description]. Defaults to 1000. policy (str, optional): Pooling policy, can be token or mean. Defaults to 'token'. \"\"\" if policy not in self . POLICIES : raise ValueError ( f \"Only policies { ',' . join ( self . POLICIES ) } are supported\" ) super () . __init__ () self . pool = ( Reduce ( \"b n e -> b e\" , reduction = \"mean\" ) if policy == \"mean\" else Lambda ( lambda x : x [:, 0 ]) ) self . fc = nn . Linear ( emb_size , num_classes ) def forward ( self , features : List [ Tensor ]) -> Tensor : x = self . pool ( features [ - 1 ]) x = self . fc ( x ) return x","title":"ViTHead"},{"location":"reference/models/vision/image/classification/heads/vit/model/#glasses.models.vision.image.classification.heads.vit.model.ViTHead.POLICIES","text":"","title":"POLICIES"},{"location":"reference/models/vision/image/classification/heads/vit/model/#glasses.models.vision.image.classification.heads.vit.model.ViTHead.fc","text":"","title":"fc"},{"location":"reference/models/vision/image/classification/heads/vit/model/#glasses.models.vision.image.classification.heads.vit.model.ViTHead.pool","text":"","title":"pool"},{"location":"reference/models/vision/image/classification/heads/vit/model/#glasses.models.vision.image.classification.heads.vit.model.ViTHead.__init__","text":"ViT Classification Head Parameters: Name Type Description Default emb_size int Embedding dimensions Defaults to 768. 768 num_classes int [description]. Defaults to 1000. 1000 policy str Pooling policy, can be token or mean. Defaults to 'token'. 'token' Source code in glasses/models/vision/image/classification/heads/vit/model.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def __init__ ( self , emb_size : int = 768 , num_classes : int = 1000 , policy : str = \"token\" ): \"\"\" ViT Classification Head Args: emb_size (int, optional): Embedding dimensions Defaults to 768. num_classes (int, optional): [description]. Defaults to 1000. policy (str, optional): Pooling policy, can be token or mean. Defaults to 'token'. \"\"\" if policy not in self . POLICIES : raise ValueError ( f \"Only policies { ',' . join ( self . POLICIES ) } are supported\" ) super () . __init__ () self . pool = ( Reduce ( \"b n e -> b e\" , reduction = \"mean\" ) if policy == \"mean\" else Lambda ( lambda x : x [:, 0 ]) ) self . fc = nn . Linear ( emb_size , num_classes )","title":"__init__()"},{"location":"reference/models/vision/image/classification/heads/vit/model/#glasses.models.vision.image.classification.heads.vit.model.ViTHead.forward","text":"Source code in glasses/models/vision/image/classification/heads/vit/model.py 35 36 37 38 def forward ( self , features : List [ Tensor ]) -> Tensor : x = self . pool ( features [ - 1 ]) x = self . fc ( x ) return x","title":"forward()"},{"location":"reference/models/vision/image/classification/vit/","text":"","title":"Index"},{"location":"reference/models/vision/image/classification/vit/config/","text":"ViTForImageClassificationConfig dataclass Bases: AnyModelForImageClassificationConfig Config for ViT model Source code in glasses/models/vision/image/classification/vit/config.py 9 10 11 12 13 14 @dataclass class ViTForImageClassificationConfig ( AnyModelForImageClassificationConfig ): \"\"\"Config for [`ViT`](/models/vision/image/classification/vit) model\"\"\" backbone_config : ViTBackboneConfig head_config : ViTHeadConfig backbone_config : ViTBackboneConfig class-attribute head_config : ViTHeadConfig class-attribute","title":"config"},{"location":"reference/models/vision/image/classification/vit/config/#glasses.models.vision.image.classification.vit.config.ViTForImageClassificationConfig","text":"Bases: AnyModelForImageClassificationConfig Config for ViT model Source code in glasses/models/vision/image/classification/vit/config.py 9 10 11 12 13 14 @dataclass class ViTForImageClassificationConfig ( AnyModelForImageClassificationConfig ): \"\"\"Config for [`ViT`](/models/vision/image/classification/vit) model\"\"\" backbone_config : ViTBackboneConfig head_config : ViTHeadConfig","title":"ViTForImageClassificationConfig"},{"location":"reference/models/vision/image/classification/vit/config/#glasses.models.vision.image.classification.vit.config.ViTForImageClassificationConfig.backbone_config","text":"","title":"backbone_config"},{"location":"reference/models/vision/image/classification/vit/config/#glasses.models.vision.image.classification.vit.config.ViTForImageClassificationConfig.head_config","text":"","title":"head_config"},{"location":"reference/models/vision/image/classification/vit/zoo/","text":"zoo = ModelZoo ( vit_small_patch16_224 = vit_small_patch16_224 , vit_base_patch16_224 = vit_base_patch16_224 , vit_base_patch16_384 = vit_base_patch16_384 ) module-attribute vit_base_patch16_224 () Source code in glasses/models/vision/image/classification/vit/zoo.py 15 16 17 18 19 20 21 def vit_base_patch16_224 (): return ViTForImageClassificationConfig ( backbone_config = ViTBackboneConfig ( depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True ), head_config = ViTHeadConfig ( 768 , 1000 ), ) vit_base_patch16_384 () Source code in glasses/models/vision/image/classification/vit/zoo.py 24 25 26 27 28 29 30 def vit_base_patch16_384 (): return ViTForImageClassificationConfig ( backbone_config = ViTBackboneConfig ( img_size = 384 , depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True ), head_config = ViTHeadConfig ( 768 , 1000 ), ) vit_small_patch16_224 () Source code in glasses/models/vision/image/classification/vit/zoo.py 8 9 10 11 12 def vit_small_patch16_224 (): return ViTForImageClassificationConfig ( backbone_config = ViTBackboneConfig ( depth = 8 , num_heads = 8 , forward_expansion = 3 ), head_config = ViTHeadConfig ( 768 , 1000 ), )","title":"zoo"},{"location":"reference/models/vision/image/classification/vit/zoo/#glasses.models.vision.image.classification.vit.zoo.zoo","text":"","title":"zoo"},{"location":"reference/models/vision/image/classification/vit/zoo/#glasses.models.vision.image.classification.vit.zoo.vit_base_patch16_224","text":"Source code in glasses/models/vision/image/classification/vit/zoo.py 15 16 17 18 19 20 21 def vit_base_patch16_224 (): return ViTForImageClassificationConfig ( backbone_config = ViTBackboneConfig ( depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True ), head_config = ViTHeadConfig ( 768 , 1000 ), )","title":"vit_base_patch16_224()"},{"location":"reference/models/vision/image/classification/vit/zoo/#glasses.models.vision.image.classification.vit.zoo.vit_base_patch16_384","text":"Source code in glasses/models/vision/image/classification/vit/zoo.py 24 25 26 27 28 29 30 def vit_base_patch16_384 (): return ViTForImageClassificationConfig ( backbone_config = ViTBackboneConfig ( img_size = 384 , depth = 12 , num_heads = 12 , forward_expansion = 4 , qkv_bias = True ), head_config = ViTHeadConfig ( 768 , 1000 ), )","title":"vit_base_patch16_384()"},{"location":"reference/models/vision/image/classification/vit/zoo/#glasses.models.vision.image.classification.vit.zoo.vit_small_patch16_224","text":"Source code in glasses/models/vision/image/classification/vit/zoo.py 8 9 10 11 12 def vit_small_patch16_224 (): return ViTForImageClassificationConfig ( backbone_config = ViTBackboneConfig ( depth = 8 , num_heads = 8 , forward_expansion = 3 ), head_config = ViTHeadConfig ( 768 , 1000 ), )","title":"vit_small_patch16_224()"},{"location":"reference/models/vision/image/detection/","text":"","title":"Index"},{"location":"reference/models/vision/image/detection/outputs/","text":"ModelForImageDetectionOutput Bases: TypedDict The output for image detection models. Source code in glasses/models/vision/image/detection/outputs.py 6 7 8 9 10 11 12 class ModelForImageDetectionOutput ( TypedDict ): \"\"\"The output for image detection models.\"\"\" logits : Tensor \"\"\"A `torch.Tensor` of shape `(batch_size, num_bboxes, num_classes + 1)`.\"\"\" bboxes : Tensor \"\"\"A `torch.Tensor` of shape `(batch_size, num_bboxes, 4)`.\"\"\" bboxes : Tensor class-attribute A torch.Tensor of shape (batch_size, num_bboxes, 4) . logits : Tensor class-attribute A torch.Tensor of shape (batch_size, num_bboxes, num_classes + 1) .","title":"outputs"},{"location":"reference/models/vision/image/detection/outputs/#glasses.models.vision.image.detection.outputs.ModelForImageDetectionOutput","text":"Bases: TypedDict The output for image detection models. Source code in glasses/models/vision/image/detection/outputs.py 6 7 8 9 10 11 12 class ModelForImageDetectionOutput ( TypedDict ): \"\"\"The output for image detection models.\"\"\" logits : Tensor \"\"\"A `torch.Tensor` of shape `(batch_size, num_bboxes, num_classes + 1)`.\"\"\" bboxes : Tensor \"\"\"A `torch.Tensor` of shape `(batch_size, num_bboxes, 4)`.\"\"\"","title":"ModelForImageDetectionOutput"},{"location":"reference/models/vision/image/detection/outputs/#glasses.models.vision.image.detection.outputs.ModelForImageDetectionOutput.bboxes","text":"A torch.Tensor of shape (batch_size, num_bboxes, 4) .","title":"bboxes"},{"location":"reference/models/vision/image/detection/outputs/#glasses.models.vision.image.detection.outputs.ModelForImageDetectionOutput.logits","text":"A torch.Tensor of shape (batch_size, num_bboxes, num_classes + 1) .","title":"logits"},{"location":"reference/models/vision/image/segmentation/","text":"","title":"Index"},{"location":"reference/models/vision/image/segmentation/outputs/","text":"ModelForImageSegmentationOutput Bases: TypedDict The output for image segmentation models. Source code in glasses/models/vision/image/segmentation/outputs.py 7 8 9 10 11 12 13 14 15 class ModelForImageSegmentationOutput ( TypedDict ): \"\"\"The output for image segmentation models.\"\"\" pixel_logits : Tensor \"\"\"A `torch.Tensor` of shape `(batch_size, num_classes, height, width)`. !!! note The `height` and `width` are usually smaller than the original image. \"\"\" pixel_logits : Tensor class-attribute A torch.Tensor of shape (batch_size, num_classes, height, width) . Note The height and width are usually smaller than the original image.","title":"outputs"},{"location":"reference/models/vision/image/segmentation/outputs/#glasses.models.vision.image.segmentation.outputs.ModelForImageSegmentationOutput","text":"Bases: TypedDict The output for image segmentation models. Source code in glasses/models/vision/image/segmentation/outputs.py 7 8 9 10 11 12 13 14 15 class ModelForImageSegmentationOutput ( TypedDict ): \"\"\"The output for image segmentation models.\"\"\" pixel_logits : Tensor \"\"\"A `torch.Tensor` of shape `(batch_size, num_classes, height, width)`. !!! note The `height` and `width` are usually smaller than the original image. \"\"\"","title":"ModelForImageSegmentationOutput"},{"location":"reference/models/vision/image/segmentation/outputs/#glasses.models.vision.image.segmentation.outputs.ModelForImageSegmentationOutput.pixel_logits","text":"A torch.Tensor of shape (batch_size, num_classes, height, width) . Note The height and width are usually smaller than the original image.","title":"pixel_logits"},{"location":"reference/models/vision/necks/","text":"","title":"Index"},{"location":"reference/models/vision/necks/base/","text":"Neck Bases: nn . Module Source code in glasses/models/vision/necks/base.py 6 7 8 class Neck ( nn . Module ): def forward ( self , features : List [ Tensor ]) -> List [ Tensor ]: raise NotImplemented forward ( features ) Source code in glasses/models/vision/necks/base.py 7 8 def forward ( self , features : List [ Tensor ]) -> List [ Tensor ]: raise NotImplemented","title":"base"},{"location":"reference/models/vision/necks/base/#glasses.models.vision.necks.base.Neck","text":"Bases: nn . Module Source code in glasses/models/vision/necks/base.py 6 7 8 class Neck ( nn . Module ): def forward ( self , features : List [ Tensor ]) -> List [ Tensor ]: raise NotImplemented","title":"Neck"},{"location":"reference/models/vision/necks/base/#glasses.models.vision.necks.base.Neck.forward","text":"Source code in glasses/models/vision/necks/base.py 7 8 def forward ( self , features : List [ Tensor ]) -> List [ Tensor ]: raise NotImplemented","title":"forward()"},{"location":"reference/nn/","text":"Lambda Bases: nn . Module Source code in glasses/nn/__init__.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Lambda ( nn . Module ): def __init__ ( self , lambd : Callable [[ Tensor ], Tensor ]): \"\"\"An utility Module, it allows custom function to be passed Args: lambd (Callable[Tensor]): A function that does something on a tensor Usage: ```python add_two = Lambda(lambd x: x + 2) add_two(Tensor([0])) // 2 ``` \"\"\" super () . __init__ () self . lambd = lambd def forward ( self , x : Tensor ) -> Tensor : return self . lambd ( x ) lambd = lambd instance-attribute __init__ ( lambd ) An utility Module, it allows custom function to be passed Parameters: Name Type Description Default lambd Callable [ Tensor ] A function that does something on a tensor required Usage: add_two = Lambda ( lambd x : x + 2 ) add_two ( Tensor ([ 0 ])) // 2 Source code in glasses/nn/__init__.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def __init__ ( self , lambd : Callable [[ Tensor ], Tensor ]): \"\"\"An utility Module, it allows custom function to be passed Args: lambd (Callable[Tensor]): A function that does something on a tensor Usage: ```python add_two = Lambda(lambd x: x + 2) add_two(Tensor([0])) // 2 ``` \"\"\" super () . __init__ () self . lambd = lambd forward ( x ) Source code in glasses/nn/__init__.py 23 24 def forward ( self , x : Tensor ) -> Tensor : return self . lambd ( x )","title":"nn"},{"location":"reference/nn/#glasses.nn.Lambda","text":"Bases: nn . Module Source code in glasses/nn/__init__.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Lambda ( nn . Module ): def __init__ ( self , lambd : Callable [[ Tensor ], Tensor ]): \"\"\"An utility Module, it allows custom function to be passed Args: lambd (Callable[Tensor]): A function that does something on a tensor Usage: ```python add_two = Lambda(lambd x: x + 2) add_two(Tensor([0])) // 2 ``` \"\"\" super () . __init__ () self . lambd = lambd def forward ( self , x : Tensor ) -> Tensor : return self . lambd ( x )","title":"Lambda"},{"location":"reference/nn/#glasses.nn.Lambda.lambd","text":"","title":"lambd"},{"location":"reference/nn/#glasses.nn.Lambda.__init__","text":"An utility Module, it allows custom function to be passed Parameters: Name Type Description Default lambd Callable [ Tensor ] A function that does something on a tensor required Usage: add_two = Lambda ( lambd x : x + 2 ) add_two ( Tensor ([ 0 ])) // 2 Source code in glasses/nn/__init__.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def __init__ ( self , lambd : Callable [[ Tensor ], Tensor ]): \"\"\"An utility Module, it allows custom function to be passed Args: lambd (Callable[Tensor]): A function that does something on a tensor Usage: ```python add_two = Lambda(lambd x: x + 2) add_two(Tensor([0])) // 2 ``` \"\"\" super () . __init__ () self . lambd = lambd","title":"__init__()"},{"location":"reference/nn/#glasses.nn.Lambda.forward","text":"Source code in glasses/nn/__init__.py 23 24 def forward ( self , x : Tensor ) -> Tensor : return self . lambd ( x )","title":"forward()"},{"location":"reference/storage/","text":"","title":"Index"},{"location":"reference/storage/base/","text":"Storage Bases: ABC Source code in glasses/storage/base.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Storage ( ABC ): @abstractmethod def put ( self , state_dict : StateDict , config : Config ): pass @abstractmethod def get ( self , key : str ) -> Tuple [ StateDict , Config ]: pass @property @abstractmethod def models ( self ) -> List [ str ]: pass def __contains__ ( self , key : str ) -> bool : return key in self . models __contains__ ( key ) Source code in glasses/storage/base.py 22 23 def __contains__ ( self , key : str ) -> bool : return key in self . models get ( key ) abstractmethod Source code in glasses/storage/base.py 13 14 15 @abstractmethod def get ( self , key : str ) -> Tuple [ StateDict , Config ]: pass models () abstractmethod property Source code in glasses/storage/base.py 17 18 19 20 @property @abstractmethod def models ( self ) -> List [ str ]: pass put ( state_dict , config ) abstractmethod Source code in glasses/storage/base.py 9 10 11 @abstractmethod def put ( self , state_dict : StateDict , config : Config ): pass","title":"base"},{"location":"reference/storage/base/#glasses.storage.base.Storage","text":"Bases: ABC Source code in glasses/storage/base.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Storage ( ABC ): @abstractmethod def put ( self , state_dict : StateDict , config : Config ): pass @abstractmethod def get ( self , key : str ) -> Tuple [ StateDict , Config ]: pass @property @abstractmethod def models ( self ) -> List [ str ]: pass def __contains__ ( self , key : str ) -> bool : return key in self . models","title":"Storage"},{"location":"reference/storage/base/#glasses.storage.base.Storage.__contains__","text":"Source code in glasses/storage/base.py 22 23 def __contains__ ( self , key : str ) -> bool : return key in self . models","title":"__contains__()"},{"location":"reference/storage/base/#glasses.storage.base.Storage.get","text":"Source code in glasses/storage/base.py 13 14 15 @abstractmethod def get ( self , key : str ) -> Tuple [ StateDict , Config ]: pass","title":"get()"},{"location":"reference/storage/base/#glasses.storage.base.Storage.models","text":"Source code in glasses/storage/base.py 17 18 19 20 @property @abstractmethod def models ( self ) -> List [ str ]: pass","title":"models()"},{"location":"reference/storage/base/#glasses.storage.base.Storage.put","text":"Source code in glasses/storage/base.py 9 10 11 @abstractmethod def put ( self , state_dict : StateDict , config : Config ): pass","title":"put()"},{"location":"reference/storage/local/","text":"LocalStorage dataclass Bases: Storage Source code in glasses/storage/local/__init__.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @dataclass class LocalStorage ( Storage ): root : Path = Path ( \"/tmp/glasses\" ) override : bool = False fmt : str = \"pth\" def __post_init__ ( self ): self . root . mkdir ( exist_ok = True ) def put ( self , key : str , state_dict : StateDict , config : Config ): save_dir = self . root / Path ( key ) save_dir . mkdir ( exist_ok = True ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" if key not in self or self . override : torch . save ( state_dict , model_save_path ) with open ( config_save_path , \"wb\" ) as f : pickle . dump ( config , f ) assert model_save_path . exists () assert config_save_path . exists () def get ( self , key : str ) -> Tuple [ StateDict , Config ]: save_dir = self . root / Path ( key ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" state_dict = torch . load ( model_save_path ) with open ( config_save_path , \"rb\" ) as f : config = pickle . load ( f ) return state_dict , config @property def models ( self ) -> List [ str ]: return [ file . stem for file in self . root . glob ( f \"*. { self . fmt } \" )] fmt : str = 'pth' class-attribute override : bool = False class-attribute root : Path = Path ( '/tmp/glasses' ) class-attribute __post_init__ () Source code in glasses/storage/local/__init__.py 20 21 def __post_init__ ( self ): self . root . mkdir ( exist_ok = True ) get ( key ) Source code in glasses/storage/local/__init__.py 36 37 38 39 40 41 42 43 def get ( self , key : str ) -> Tuple [ StateDict , Config ]: save_dir = self . root / Path ( key ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" state_dict = torch . load ( model_save_path ) with open ( config_save_path , \"rb\" ) as f : config = pickle . load ( f ) return state_dict , config models () property Source code in glasses/storage/local/__init__.py 45 46 47 @property def models ( self ) -> List [ str ]: return [ file . stem for file in self . root . glob ( f \"*. { self . fmt } \" )] put ( key , state_dict , config ) Source code in glasses/storage/local/__init__.py 23 24 25 26 27 28 29 30 31 32 33 34 def put ( self , key : str , state_dict : StateDict , config : Config ): save_dir = self . root / Path ( key ) save_dir . mkdir ( exist_ok = True ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" if key not in self or self . override : torch . save ( state_dict , model_save_path ) with open ( config_save_path , \"wb\" ) as f : pickle . dump ( config , f ) assert model_save_path . exists () assert config_save_path . exists ()","title":"local"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage","text":"Bases: Storage Source code in glasses/storage/local/__init__.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @dataclass class LocalStorage ( Storage ): root : Path = Path ( \"/tmp/glasses\" ) override : bool = False fmt : str = \"pth\" def __post_init__ ( self ): self . root . mkdir ( exist_ok = True ) def put ( self , key : str , state_dict : StateDict , config : Config ): save_dir = self . root / Path ( key ) save_dir . mkdir ( exist_ok = True ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" if key not in self or self . override : torch . save ( state_dict , model_save_path ) with open ( config_save_path , \"wb\" ) as f : pickle . dump ( config , f ) assert model_save_path . exists () assert config_save_path . exists () def get ( self , key : str ) -> Tuple [ StateDict , Config ]: save_dir = self . root / Path ( key ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" state_dict = torch . load ( model_save_path ) with open ( config_save_path , \"rb\" ) as f : config = pickle . load ( f ) return state_dict , config @property def models ( self ) -> List [ str ]: return [ file . stem for file in self . root . glob ( f \"*. { self . fmt } \" )]","title":"LocalStorage"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage.fmt","text":"","title":"fmt"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage.override","text":"","title":"override"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage.root","text":"","title":"root"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage.__post_init__","text":"Source code in glasses/storage/local/__init__.py 20 21 def __post_init__ ( self ): self . root . mkdir ( exist_ok = True )","title":"__post_init__()"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage.get","text":"Source code in glasses/storage/local/__init__.py 36 37 38 39 40 41 42 43 def get ( self , key : str ) -> Tuple [ StateDict , Config ]: save_dir = self . root / Path ( key ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" state_dict = torch . load ( model_save_path ) with open ( config_save_path , \"rb\" ) as f : config = pickle . load ( f ) return state_dict , config","title":"get()"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage.models","text":"Source code in glasses/storage/local/__init__.py 45 46 47 @property def models ( self ) -> List [ str ]: return [ file . stem for file in self . root . glob ( f \"*. { self . fmt } \" )]","title":"models()"},{"location":"reference/storage/local/#glasses.storage.local.LocalStorage.put","text":"Source code in glasses/storage/local/__init__.py 23 24 25 26 27 28 29 30 31 32 33 34 def put ( self , key : str , state_dict : StateDict , config : Config ): save_dir = self . root / Path ( key ) save_dir . mkdir ( exist_ok = True ) model_save_path = save_dir / \"model. {self.fmt} \" config_save_path = save_dir / \"config.pkl\" if key not in self or self . override : torch . save ( state_dict , model_save_path ) with open ( config_save_path , \"wb\" ) as f : pickle . dump ( config , f ) assert model_save_path . exists () assert config_save_path . exists ()","title":"put()"},{"location":"tutorial/coding-style/","text":"In order to properly create a truly amazing codebase, we must agree on some conding conventions. We follow the PEP 8 style guide for Python Code. Naming Convention Names We are lazy programmers! Keep the variables names short but meaningfull: convolution -> conv activation -> act linear/dense -> fc batchnorm -> bn ... etc Models Block : we refer to Block to mean a minimum building block of a model. Stage : a Stage is a collection of Block s A model is always linked to a task. Therefore, each model follows the <ModelName>For<TaskName> naming convention. FOr example, ResNetForImageClassification . When you have something very simple, you can directly subclass nn.Sequential to avoid writing a trivial forward function. # This module is trivial, use nn.Sequential instead! class ConvBnReLU ( nn . Module ): def __init__ ( self , ... ): super () . __init__ () self . conv = nn . Conv2d ( ... ) self . bn = nn . BatchNorm2d ( ... ) self . relu = nn . ReLU () def forward ( self , x ): x = self . conv ( x ) x = self . bn ( x ) x = self . relu ( x ) return x # no need for the forward class ConvBnReLU ( nn . Sequential ): def __init__ ( self , ... ): super () . __init__ () self . conv = nn . Conv2d ( ... ) self . bn = nn . BatchNorm2d ( ... ) self . relu = nn . ReLU () Design We follow the single responsability principle where each class/function does only one thing. For example, assume we have the following model (we are subclassing nn.Sequential for simplicity). class MyModel ( nn . Module ): def __init__ ( ... ): super () . __init__ () self . embedder = nn . Sequential ( nn . Conv2d ( .... ), nn . BatchNorm2d ( ... ), nn . ReLU () ) self . encoder = nn . Sequential ( nn . Conv2d ( ... ), nn . Conv2d ( ... ), nn . Conv2d ( ... ) ) self . head = nn . Sequential ( nn . Linear ( ... ) ) class MyModelEmbedder ( nn . Sequential ): def __init__ ( ... ): super () . __init__ ( nn . Conv2d ( ... ), nn . BatchNorm2d ( ... ), nn . ReLU () ) class MyModelEncoder ( nn . Sequential ): def __init__ ( ... ): super () . __init__ ( nn . Conv2d ( ... ), nn . Conv2d ( ... ), nn . Conv2d ( ... ) ) class MyModelHead ( nn . Sequential ): def __init__ ( ... ): super () . __init__ ( nn . Linear ( ... )) class MyModel ( nn . Module ): def __init__ ( ... ): super () . __init__ () self . embedder = MyModelEmbedder ( ... ) self . encoder = MyModelEncoder ( ... ) self . head = MyModelHead ( ... ) Each module does only one thing. This makes it easier to document and share each individual parts.","title":"Coding style"},{"location":"tutorial/coding-style/#naming-convention","text":"","title":"Naming Convention"},{"location":"tutorial/coding-style/#names","text":"We are lazy programmers! Keep the variables names short but meaningfull: convolution -> conv activation -> act linear/dense -> fc batchnorm -> bn ... etc","title":"Names"},{"location":"tutorial/coding-style/#models","text":"Block : we refer to Block to mean a minimum building block of a model. Stage : a Stage is a collection of Block s A model is always linked to a task. Therefore, each model follows the <ModelName>For<TaskName> naming convention. FOr example, ResNetForImageClassification . When you have something very simple, you can directly subclass nn.Sequential to avoid writing a trivial forward function. # This module is trivial, use nn.Sequential instead! class ConvBnReLU ( nn . Module ): def __init__ ( self , ... ): super () . __init__ () self . conv = nn . Conv2d ( ... ) self . bn = nn . BatchNorm2d ( ... ) self . relu = nn . ReLU () def forward ( self , x ): x = self . conv ( x ) x = self . bn ( x ) x = self . relu ( x ) return x # no need for the forward class ConvBnReLU ( nn . Sequential ): def __init__ ( self , ... ): super () . __init__ () self . conv = nn . Conv2d ( ... ) self . bn = nn . BatchNorm2d ( ... ) self . relu = nn . ReLU ()","title":"Models"},{"location":"tutorial/coding-style/#design","text":"We follow the single responsability principle where each class/function does only one thing. For example, assume we have the following model (we are subclassing nn.Sequential for simplicity). class MyModel ( nn . Module ): def __init__ ( ... ): super () . __init__ () self . embedder = nn . Sequential ( nn . Conv2d ( .... ), nn . BatchNorm2d ( ... ), nn . ReLU () ) self . encoder = nn . Sequential ( nn . Conv2d ( ... ), nn . Conv2d ( ... ), nn . Conv2d ( ... ) ) self . head = nn . Sequential ( nn . Linear ( ... ) ) class MyModelEmbedder ( nn . Sequential ): def __init__ ( ... ): super () . __init__ ( nn . Conv2d ( ... ), nn . BatchNorm2d ( ... ), nn . ReLU () ) class MyModelEncoder ( nn . Sequential ): def __init__ ( ... ): super () . __init__ ( nn . Conv2d ( ... ), nn . Conv2d ( ... ), nn . Conv2d ( ... ) ) class MyModelHead ( nn . Sequential ): def __init__ ( ... ): super () . __init__ ( nn . Linear ( ... )) class MyModel ( nn . Module ): def __init__ ( ... ): super () . __init__ () self . embedder = MyModelEmbedder ( ... ) self . encoder = MyModelEncoder ( ... ) self . head = MyModelHead ( ... ) Each module does only one thing. This makes it easier to document and share each individual parts.","title":"Design"},{"location":"tutorial/configurations/","text":"Glasses uses a configuration system to record/share and load custom versions of a specific architecture. Note Configurations in glasses are python dataclasses , thus at any point in time, you can import them and know exactly what goes inside. The main idea behind our configuration system is to be an addition to the models, not a requirement . Any model in classes can be created by just importing it and passing the right parameters, they don't know about configurations. Saying that, why do we need configurations? Configurations are necessary when we need to store a specific set of parameters for a model. For example, if a model was trained on dataset X with ten classes, our configuration will contain all the parameters need to create that specific model. In most libraries, configurations are serialized files (e.g. yml ), in glasses, they are code. This allows the user to take advantage of its IDE and see the parameters at any point in time. Basic Config Let's see how to create a basic config. First, we need a model from torch import nn class MyModel ( nn . Module ): def __init__ ( in_channels : int , out_channels : int ): super () . __init__ () self . conv = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 ) def forward ( self , x ): return self . conv ( x ) Then we can create it's configuration from glasses.config import Config # Let's create it's configuration @dataclass class MyConfig ( Config ): in_channels : int out_channels : int def build ( self ) -> nn . Module : # create a `MyModel` instance using `MyConfig` return MyModel ( ** self . __dict__ ) We can now invoke the build method, which will create the model model : MyModel = MyConfig ( 2 , 2 ) . build () # same as model : MyModel = MyModel ( 2 , 2 ) Nothing very special. Nested Config Let's see how to create a nested config . Assume we have a model that takes a backbone and has a fixed head. from torch import nn class MyModel ( nn . Module ): def __init__ ( self , backbone : nn . Module , channels : int , num_classes : int ): super () . __init__ () self . backbone = backbone self . head = nn . Conv2d ( channels , num_classes , kernel_size = 1 ) def forward ( self , x ): features = self . backbone ( x ) out = self . head ( features [ - 1 ]) # use last feature return out Our config will be nested since backbone has its own configuration. from glasses.config import Config @dataclass class MyConfig ( Config ): backbone_config : Config channels : int num_classes : int def build ( self ) -> nn . Module : backbone = backbone_config . build () # create a `MyModel` instance using `MyConfig` return MyModel ( backbone , self . channels , self . num_classes ) As expected, we must have configs for the different backbones we want to use. from torch import nn from glasses.config import Config class BackboneA ( nn . Module ): def __init__ ( ... ): ... @dataclass class BackboneAConfig ( Config ): ... class BackboneB ( nn . Module ): def __init__ ( ... ): .... @dataclass class BackboneBConfig ( Config ): ... Then, we can pass any backbone to MyConfig . config = MyConfig ( backbone_config = BackboneAConfig ( ... ), ... ) config . build () # build model with backbone A config = MyConfig ( backbone_config = BackboneBConfig ( ... ), ... ) config . build () # build model with backbone B The main advantage of the config system is when we need to save a specific model version. For instance, assume I have trained MyModel with BackboneA on dataset X . Its config will look like this: my_model_backbone_a_x = MyConfig ( backbone_config = BackboneAConfig ( ... ), channels = 64 , num_classes = 10 ) Therefore, at any point in time, I can recreate the model and load its pretrained weights. my_model_backbone_a_x . build () . load_state_dict ( \"/somewhere/my_model_backbone_a_x.pth\" ) Now, what if I want to use my_model_backbone_a_x architecture but just change a small part? Maybe the number of classes? # clone the config config = MyConfig ( ** my_model_backbone_a_x . __dict__ ) config . num_classes = 8 # load the pretrained weight, with a different number of classes config . build () . load_state_dict ( \"/somewhere/my_model_backbone_a_x.pth\" ) If you have any issues, feel free to open one on GitHub","title":"Configurations"},{"location":"tutorial/configurations/#basic-config","text":"Let's see how to create a basic config. First, we need a model from torch import nn class MyModel ( nn . Module ): def __init__ ( in_channels : int , out_channels : int ): super () . __init__ () self . conv = nn . Conv2d ( in_channels , out_channels , kernel_size = 1 ) def forward ( self , x ): return self . conv ( x ) Then we can create it's configuration from glasses.config import Config # Let's create it's configuration @dataclass class MyConfig ( Config ): in_channels : int out_channels : int def build ( self ) -> nn . Module : # create a `MyModel` instance using `MyConfig` return MyModel ( ** self . __dict__ ) We can now invoke the build method, which will create the model model : MyModel = MyConfig ( 2 , 2 ) . build () # same as model : MyModel = MyModel ( 2 , 2 ) Nothing very special.","title":"Basic Config"},{"location":"tutorial/configurations/#nested-config","text":"Let's see how to create a nested config . Assume we have a model that takes a backbone and has a fixed head. from torch import nn class MyModel ( nn . Module ): def __init__ ( self , backbone : nn . Module , channels : int , num_classes : int ): super () . __init__ () self . backbone = backbone self . head = nn . Conv2d ( channels , num_classes , kernel_size = 1 ) def forward ( self , x ): features = self . backbone ( x ) out = self . head ( features [ - 1 ]) # use last feature return out Our config will be nested since backbone has its own configuration. from glasses.config import Config @dataclass class MyConfig ( Config ): backbone_config : Config channels : int num_classes : int def build ( self ) -> nn . Module : backbone = backbone_config . build () # create a `MyModel` instance using `MyConfig` return MyModel ( backbone , self . channels , self . num_classes ) As expected, we must have configs for the different backbones we want to use. from torch import nn from glasses.config import Config class BackboneA ( nn . Module ): def __init__ ( ... ): ... @dataclass class BackboneAConfig ( Config ): ... class BackboneB ( nn . Module ): def __init__ ( ... ): .... @dataclass class BackboneBConfig ( Config ): ... Then, we can pass any backbone to MyConfig . config = MyConfig ( backbone_config = BackboneAConfig ( ... ), ... ) config . build () # build model with backbone A config = MyConfig ( backbone_config = BackboneBConfig ( ... ), ... ) config . build () # build model with backbone B The main advantage of the config system is when we need to save a specific model version. For instance, assume I have trained MyModel with BackboneA on dataset X . Its config will look like this: my_model_backbone_a_x = MyConfig ( backbone_config = BackboneAConfig ( ... ), channels = 64 , num_classes = 10 ) Therefore, at any point in time, I can recreate the model and load its pretrained weights. my_model_backbone_a_x . build () . load_state_dict ( \"/somewhere/my_model_backbone_a_x.pth\" ) Now, what if I want to use my_model_backbone_a_x architecture but just change a small part? Maybe the number of classes? # clone the config config = MyConfig ( ** my_model_backbone_a_x . __dict__ ) config . num_classes = 8 # load the pretrained weight, with a different number of classes config . build () . load_state_dict ( \"/somewhere/my_model_backbone_a_x.pth\" ) If you have any issues, feel free to open one on GitHub","title":"Nested Config"}]}